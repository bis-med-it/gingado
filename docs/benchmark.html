<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Functions to create a relevant, fast and reasonably well-performing benchmark">

<title>gingado - Automatic benchmark model</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="gingado - Automatic benchmark model">
<meta property="og:description" content="Functions to create a relevant, fast and reasonably well-performing benchmark">
<meta property="og:site-name" content="gingado">
<meta name="twitter:title" content="gingado - Automatic benchmark model">
<meta name="twitter:description" content="Functions to create a relevant, fast and reasonably well-performing benchmark">
<meta name="twitter:creator" content="@DouglasKGAraujo">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">gingado</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-examples" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Examples</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-examples">    
        <li>
    <a class="dropdown-item" href="./barrolee1994.html" rel="" target="">
 <span class="dropdown-text">Economic growth</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./forecast.html" rel="" target="">
 <span class="dropdown-text">Forecasting FX rates</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./machine_controls.html" rel="" target="">
 <span class="dropdown-text">Effects of labour reform</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-reference" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Reference</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-reference">    
        <li>
    <a class="dropdown-item" href="./augmentation.html" rel="" target="">
 <span class="dropdown-text">gingado.augmentation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./datasets.html" rel="" target="">
 <span class="dropdown-text">gingado.datasets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./benchmark.html" rel="" target="">
 <span class="dropdown-text">gingado.benchmark</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./estimators.html" rel="" target="">
 <span class="dropdown-text">gingado.estimators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./documentation.html" rel="" target="">
 <span class="dropdown-text">gingado.model_documentation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./utils.html" rel="" target="">
 <span class="dropdown-text">gingado.utils</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/dkgaraujo/gingado" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/DouglasKGARaujo" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#base-class" id="toc-base-class" class="nav-link active" data-scroll-target="#base-class">Base class</a>
  <ul>
  <li><a href="#ggdbenchmark" id="toc-ggdbenchmark" class="nav-link" data-scroll-target="#ggdbenchmark"></a><a id="ggdbenchmark" class="nav-link" data-scroll-target="undefined">ggdBenchmark</a>
  <ul class="collapse">
  <li><a href="#compare" id="toc-compare" class="nav-link" data-scroll-target="#compare"></a><a id="compare" class="nav-link" data-scroll-target="undefined">compare</a></li>
  <li><a href="#compare_fitted_candidates" id="toc-compare_fitted_candidates" class="nav-link" data-scroll-target="#compare_fitted_candidates"></a><a id="compare_fitted_candidates" class="nav-link" data-scroll-target="undefined">compare_fitted_candidates</a></li>
  <li><a href="#document" id="toc-document" class="nav-link" data-scroll-target="#document"></a><a id="document" class="nav-link" data-scroll-target="undefined">document</a></li>
  <li><a href="#predict" id="toc-predict" class="nav-link" data-scroll-target="#predict"></a><a id="predict" class="nav-link" data-scroll-target="undefined">predict</a></li>
  <li><a href="#fit_predict" id="toc-fit_predict" class="nav-link" data-scroll-target="#fit_predict"></a><a id="fit_predict" class="nav-link" data-scroll-target="undefined">fit_predict</a></li>
  <li><a href="#predict_proba" id="toc-predict_proba" class="nav-link" data-scroll-target="#predict_proba"></a><a id="predict_proba" class="nav-link" data-scroll-target="undefined">predict_proba</a></li>
  <li><a href="#predict_log_proba" id="toc-predict_log_proba" class="nav-link" data-scroll-target="#predict_log_proba"></a><a id="predict_log_proba" class="nav-link" data-scroll-target="undefined">predict_log_proba</a></li>
  <li><a href="#decision_function" id="toc-decision_function" class="nav-link" data-scroll-target="#decision_function"></a><a id="decision_function" class="nav-link" data-scroll-target="undefined">decision_function</a></li>
  <li><a href="#score" id="toc-score" class="nav-link" data-scroll-target="#score"></a><a id="score" class="nav-link" data-scroll-target="undefined">score</a></li>
  <li><a href="#score_samples" id="toc-score_samples" class="nav-link" data-scroll-target="#score_samples"></a><a id="score_samples" class="nav-link" data-scroll-target="undefined">score_samples</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#classification-tasks" id="toc-classification-tasks" class="nav-link" data-scroll-target="#classification-tasks">Classification tasks</a>
  <ul>
  <li><a href="#classificationbenchmark" id="toc-classificationbenchmark" class="nav-link" data-scroll-target="#classificationbenchmark"></a><a id="classificationbenchmark" class="nav-link" data-scroll-target="undefined">ClassificationBenchmark</a>
  <ul class="collapse">
  <li><a href="#fit" id="toc-fit" class="nav-link" data-scroll-target="#fit"></a><a id="fit" class="nav-link" data-scroll-target="undefined">fit</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#regression-tasks" id="toc-regression-tasks" class="nav-link" data-scroll-target="#regression-tasks">Regression tasks</a>
  <ul>
  <li><a href="#regressionbenchmark" id="toc-regressionbenchmark" class="nav-link" data-scroll-target="#regressionbenchmark"></a><a id="regressionbenchmark" class="nav-link" data-scroll-target="undefined">RegressionBenchmark</a>
  <ul class="collapse">
  <li><a href="#fit-1" id="toc-fit-1" class="nav-link" data-scroll-target="#fit-1"></a><a id="fit" class="nav-link" data-scroll-target="undefined">fit</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#general-comments-on-benchmarks" id="toc-general-comments-on-benchmarks" class="nav-link" data-scroll-target="#general-comments-on-benchmarks">General comments on benchmarks</a>
  <ul>
  <li><a href="#scoring" id="toc-scoring" class="nav-link" data-scroll-target="#scoring">Scoring</a></li>
  <li><a href="#data-split" id="toc-data-split" class="nav-link" data-scroll-target="#data-split">Data split</a></li>
  <li><a href="#custom-benchmarks" id="toc-custom-benchmarks" class="nav-link" data-scroll-target="#custom-benchmarks">Custom benchmarks</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Automatic benchmark model</h1>
</div>

<div>
  <div class="description">
    Functions to create a relevant, fast and reasonably well-performing benchmark
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>A Benchmark object has a similar API to a <code>sciki-learn</code> estimator: you build an instance with the desired arguments, and fit it to the data at a later moment. Benchmarks is a convenience wrapper for reading the training data, passing it through a simplified pipeline consisting of data imputation and a standard scalar, and then the benchmark function calibrated with a grid search.</p>
<p>A <code>gingado</code> Benchmark object seeks to automatise a significant part of creating a benchmark model. Importantly, the Benchmark object also has a <code>compare</code> method that helps users evaluate if candidate models are better than the benchmark, and if one of them is, it becomes the new benchmark. This <code>compare</code> method takes as argument another fitted estimator (which could be itself a solo estimator or a whole pipeline) or a list of fitted estimators.</p>
<p>Benchmarks start with default values that should perform reasonably well in most settings, but the user is also free to choose any of the benchmark’s components by passing as arguments the data split, pipeline, and/or a dictionary of parameters for the hyperparameter tuning.</p>
<section id="base-class" class="level1">
<h1>Base class</h1>
<p><code>gingado</code> has a <code>ggdBenchmark</code> base class that contains the basic functionalities for Benchmark objects. It is not meant to be used by itself, but only as a hyperclass for Benchmark objects. <code>gingado</code> ships with two of these objects that subclass <code>ggdBenchmark</code>: <code>ClassificationBenchmark</code> and <code>RegressionBenchmark</code>. They are both described below in their respective sections.</p>
<p>Users are encouraged to submit a PR with their own benchmark models subclassing <code>ggdBenchmark</code>.</p>
<section id="ggdbenchmark" class="level3">
<h3 class="anchored" data-anchor-id="ggdbenchmark"><a id="ggdbenchmark">ggdBenchmark</a></h3>
<blockquote class="blockquote">
<p>ggdBenchmark <code>()</code></p>
</blockquote>
<pre>The base class for gingado's Benchmark objects.

This class provides the foundational functionality for benchmarking models, including
setting up data splitters for time series data, fitting models, and comparing candidate models.</pre>
<section id="compare" class="level4">
<h4 class="anchored" data-anchor-id="compare"><a id="compare">compare</a></h4>
<blockquote class="blockquote">
<p>compare <code>(self, X: 'np.ndarray', y: 'np.ndarray', candidates, ensemble_method='object_default', update_benchmark: 'bool' = True)</code></p>
</blockquote>
<pre>Compares the performance of the benchmark model with candidate models.

Args:
    X: Input data of shape (n_samples, n_features).
    y: Target data of shape (n_samples,) or (n_samples, n_targets).
    candidates: Candidate estimator(s) for comparison.
    ensemble_method: Method to combine candidate estimators. Default is 'object_default'.
    update_benchmark: Whether to update the benchmark with the best performing model. Default is True.</pre>
</section>
<section id="compare_fitted_candidates" class="level4">
<h4 class="anchored" data-anchor-id="compare_fitted_candidates"><a id="compare_fitted_candidates">compare_fitted_candidates</a></h4>
<blockquote class="blockquote">
<p>compare_fitted_candidates <code>(self, X, y, candidates, scoring_func)</code></p>
</blockquote>
<pre>No documentation available.</pre>
</section>
<section id="document" class="level4">
<h4 class="anchored" data-anchor-id="document"><a id="document">document</a></h4>
<blockquote class="blockquote">
<p>document <code>(self, documenter: 'ggdModelDocumentation | None' = None)</code></p>
</blockquote>
<pre>Documents the benchmark model using the specified template.

Args:
    documenter: A gingado Documenter or the documenter set in `auto_document`. Default is None.</pre>
</section>
<section id="predict" class="level4">
<h4 class="anchored" data-anchor-id="predict"><a id="predict">predict</a></h4>
<blockquote class="blockquote">
<p>predict <code>(self, X, **predict_params)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
<section id="fit_predict" class="level4">
<h4 class="anchored" data-anchor-id="fit_predict"><a id="fit_predict">fit_predict</a></h4>
<blockquote class="blockquote">
<p>fit_predict <code>(self, X, y=None, **predict_params)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
<section id="predict_proba" class="level4">
<h4 class="anchored" data-anchor-id="predict_proba"><a id="predict_proba">predict_proba</a></h4>
<blockquote class="blockquote">
<p>predict_proba <code>(self, X, **predict_proba_params)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
<section id="predict_log_proba" class="level4">
<h4 class="anchored" data-anchor-id="predict_log_proba"><a id="predict_log_proba">predict_log_proba</a></h4>
<blockquote class="blockquote">
<p>predict_log_proba <code>(self, X, **predict_log_proba_params)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
<section id="decision_function" class="level4">
<h4 class="anchored" data-anchor-id="decision_function"><a id="decision_function">decision_function</a></h4>
<blockquote class="blockquote">
<p>decision_function <code>(self, X)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
<section id="score" class="level4">
<h4 class="anchored" data-anchor-id="score"><a id="score">score</a></h4>
<blockquote class="blockquote">
<p>score <code>(self, X)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
<section id="score_samples" class="level4">
<h4 class="anchored" data-anchor-id="score_samples"><a id="score_samples">score_samples</a></h4>
<blockquote class="blockquote">
<p>score_samples <code>(self, X)</code></p>
</blockquote>
<pre>Note: only available if the benchmark implements this method.</pre>
</section>
</section>
</section>
<section id="classification-tasks" class="level1">
<h1>Classification tasks</h1>
<p>The default benchmark for classification tasks is a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"><code>RandomForestClassifier</code></a> object. Its parameters are fine-tuned in each case according to the user’s data.</p>
<section id="classificationbenchmark" class="level3">
<h3 class="anchored" data-anchor-id="classificationbenchmark"><a id="classificationbenchmark">ClassificationBenchmark</a></h3>
<blockquote class="blockquote">
<p>ClassificationBenchmark <code>(cv=None, default_cv=StratifiedShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), estimator=RandomForestClassifier(oob_score=True), param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, param_search=&lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;, scoring=None, auto_document=&lt;class 'gingado.model_documentation.ModelCard'&gt;, random_state=None, verbose_grid=False, ensemble_method=&lt;class 'sklearn.ensemble._voting.VotingClassifier'&gt;)</code></p>
</blockquote>
<pre>A gingado Benchmark object used for classification tasks</pre>
<section id="fit" class="level4">
<h4 class="anchored" data-anchor-id="fit"><a id="fit">fit</a></h4>
<blockquote class="blockquote">
<p>fit <code>(self, X: 'np.ndarray', y: 'np.ndarray | None' = None)</code></p>
</blockquote>
<pre>Fit the ClassificationBenchmark model.

Args:
    X (np.ndarray): Array-like data of shape (n_samples, n_features), representing the input data.
    y (np.ndarray, optional): Array-like data of shape (n_samples,) or (n_samples, n_targets), representing the target values. Defaults to None.

Returns:
    ClassificationBenchmark: The instance of the model after fitting.</pre>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_classification</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># some mock up data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># the gingado benchmark</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>bm <span class="op">=</span> ClassificationBenchmark(verbose_grid<span class="op">=</span><span class="dv">2</span>).fit(X, y)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># note that now the `bm` object can be used as an estimator</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> bm.predict(X).shape <span class="op">==</span> y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.2s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.6s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.9s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   1.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.8s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.8s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.5s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.2s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.2s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.2s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.9s
[CV] END ................max_features=log2, n_estimators=250; total time=   1.2s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.5s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.5s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.9s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.7s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.7s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.4s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.1s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.1s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.5s
[CV] END ................max_features=None, n_estimators=250; total time=   0.5s
[CV] END ................max_features=None, n_estimators=250; total time=   0.5s
[CV] END ................max_features=None, n_estimators=250; total time=   0.6s
[CV] END ................max_features=None, n_estimators=250; total time=   0.6s
[CV] END ................max_features=None, n_estimators=250; total time=   0.6s
[CV] END ................max_features=None, n_estimators=250; total time=   0.6s
[CV] END ................max_features=None, n_estimators=250; total time=   0.4s
[CV] END ................max_features=None, n_estimators=250; total time=   0.4s
[CV] END ................max_features=None, n_estimators=250; total time=   0.5s</code></pre>
</div>
</div>
<p>Importantly, <code>gingado</code> automatically provides some information to help the user documentat the benchmark model. More specifically, <code>ggdBenchmark</code> objects collect model information and pass it to a dictionary with key <code>info</code> in a field called <code>model_details</code>.</p>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>bm.model_documentation.show_json()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>{'model_details': {'developer': 'Person or organisation developing the model',
  'datetime': '2024-02-22 14:51:06 ',
  'version': 'Model version',
  'type': 'Model type',
  'info': {'_estimator_type': 'classifier',
   'best_estimator_': RandomForestClassifier(oob_score=True),
   'best_index_': 0,
   'best_params_': {'max_features': 'sqrt', 'n_estimators': 100},
   'best_score_': 0.9000000000000001,
   'classes_': array([0, 1]),
   'cv_results_': {'mean_fit_time': array([0.19240494, 0.69771829, 0.24500697, 0.73312016, 0.26230736,
           0.62561612]),
    'std_fit_time': array([0.02142618, 0.25486954, 0.07672787, 0.26078018, 0.02283094,
           0.06093919]),
    'mean_score_time': array([0.00690031, 0.01380079, 0.00940042, 0.01439977, 0.00580022,
           0.01180046]),
    'std_score_time': array([0.00332973, 0.00312462, 0.00683   , 0.00352702, 0.00060164,
           0.00153665]),
    'param_max_features': masked_array(data=['sqrt', 'sqrt', 'log2', 'log2', None, None],
                 mask=[False, False, False, False, False, False],
           fill_value='?',
                dtype=object),
    'param_n_estimators': masked_array(data=[100, 250, 100, 250, 100, 250],
                 mask=[False, False, False, False, False, False],
           fill_value='?',
                dtype=object),
    'params': [{'max_features': 'sqrt', 'n_estimators': 100},
     {'max_features': 'sqrt', 'n_estimators': 250},
     {'max_features': 'log2', 'n_estimators': 100},
     {'max_features': 'log2', 'n_estimators': 250},
     {'max_features': None, 'n_estimators': 100},
     {'max_features': None, 'n_estimators': 250}],
    'split0_test_score': array([0.7, 0.7, 0.8, 0.7, 0.7, 0.7]),
    'split1_test_score': array([1., 1., 1., 1., 1., 1.]),
    'split2_test_score': array([0.9, 0.9, 0.9, 0.9, 0.9, 0.9]),
    'split3_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8]),
    'split4_test_score': array([0.9, 0.9, 0.9, 0.9, 0.9, 0.9]),
    'split5_test_score': array([1. , 1. , 1. , 1. , 0.9, 0.9]),
    'split6_test_score': array([1. , 1. , 1. , 1. , 0.9, 0.9]),
    'split7_test_score': array([0.8, 0.8, 0.8, 0.8, 0.8, 0.8]),
    'split8_test_score': array([1. , 1. , 0.9, 1. , 1. , 1. ]),
    'split9_test_score': array([0.9, 0.8, 0.8, 0.8, 0.8, 0.8]),
    'mean_test_score': array([0.9 , 0.89, 0.89, 0.89, 0.87, 0.87]),
    'std_test_score': array([0.1       , 0.10440307, 0.08306624, 0.10440307, 0.09      ,
           0.09      ]),
    'rank_test_score': array([1, 2, 4, 2, 5, 5])},
   'multimetric_': False,
   'n_features_in_': 20,
   'n_splits_': 10,
   'refit_time_': 0.20300769805908203,
   'scorer_': &lt;sklearn.metrics._scorer._PassthroughScorer at 0x2d3e17b24f0&gt;},
  'paper': 'Paper or other resource for more information',
  'citation': 'Citation details',
  'license': 'License',
  'contact': 'Where to send questions or comments about the model'},
 'intended_use': {'primary_uses': 'Primary intended uses',
  'primary_users': 'Primary intended users',
  'out_of_scope': 'Out-of-scope use cases'},
 'factors': {'relevant': 'Relevant factors',
  'evaluation': 'Evaluation factors'},
 'metrics': {'performance_measures': 'Model performance measures',
  'thresholds': 'Decision thresholds',
  'variation_approaches': 'Variation approaches'},
 'evaluation_data': {'datasets': 'Datasets',
  'motivation': 'Motivation',
  'preprocessing': 'Preprocessing'},
 'training_data': {'training_data': 'Information on training data'},
 'quant_analyses': {'unitary': 'Unitary results',
  'intersectional': 'Intersectional results'},
 'ethical_considerations': {'sensitive_data': 'Does the model use any sensitive data (e.g., protected classes)?',
  'human_life': 'Is the model intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?',
  'mitigations': 'What risk mitigation strategies were used during model development?',
  'risks_and_harms': 'What risks may be present in model usage? Try to identify the potential recipients,likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown',
  'use_cases': 'Are there any known model use cases that are especially fraught?',
  'additional_information': 'If possible, this section should also include any additional ethical considerations that went into model development, for example, review by an external board, or testing with a specific community.'},
 'caveats_recommendations': {'caveats': 'For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?',
  'recommendations': 'Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?'}}</code></pre>
</div>
</div>
<p>It is also simple to define as benchmark a model that you already fitted and still benefit from the other functionalities provided by <code>Benchmark</code> class. This can also be done in case you are using a saved version of a fitted model (eg, the model you are using in production) and want to have that as the benchmark.</p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>forest <span class="op">=</span> RandomForestClassifier().fit(X, y)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>bm.set_benchmark(estimator<span class="op">=</span>forest)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> forest <span class="op">==</span> bm.benchmark</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">hasattr</span>(bm.benchmark, <span class="st">"predict"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> bm.predict(X).shape <span class="op">==</span> y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
</section>
<section id="regression-tasks" class="level1">
<h1>Regression tasks</h1>
<p>The default benchmark for regression tasks is a <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"><code>RandomForestRegressor</code></a> object. Its parameters are fine-tuned in each case according to the user’s data.</p>
<section id="regressionbenchmark" class="level3">
<h3 class="anchored" data-anchor-id="regressionbenchmark"><a id="regressionbenchmark">RegressionBenchmark</a></h3>
<blockquote class="blockquote">
<p>RegressionBenchmark <code>(cv=None, default_cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), estimator=RandomForestRegressor(oob_score=True), param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, param_search=&lt;class 'sklearn.model_selection._search.GridSearchCV'&gt;, scoring=None, auto_document=&lt;class 'gingado.model_documentation.ModelCard'&gt;, random_state=None, verbose_grid=False, ensemble_method=&lt;class 'sklearn.ensemble._voting.VotingRegressor'&gt;)</code></p>
</blockquote>
<pre>A gingado Benchmark object used for regression tasks</pre>
<section id="fit-1" class="level4">
<h4 class="anchored" data-anchor-id="fit-1"><a id="fit">fit</a></h4>
<blockquote class="blockquote">
<p>fit <code>(self, X: 'np.ndarray', y: 'np.ndarray | None' = None)</code></p>
</blockquote>
<pre>Fit the `RegressionBenchmark` model.

Args:
    X (np.ndarray): Array-like data of shape (n_samples, n_features).
    y (np.ndarray | None, optional): Array-like data of shape (n_samples,) or (n_samples, n_targets) or None. Defaults to None.

Returns:
    RegressionBenchmark: The instance of the model.</pre>
<div class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_regression</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> AdaBoostRegressor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># some mock up data</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_regression()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># the gingado benchmark</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>bm <span class="op">=</span> RegressionBenchmark().fit(X, y)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># note that now the `bm` object can be used as an estimator</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> bm.predict(X).shape <span class="op">==</span> y.shape</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co"># the user might also like to set another model as the benchmark</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>adaboost <span class="op">=</span> AdaBoostRegressor().fit(X, y)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>bm.set_benchmark(estimator<span class="op">=</span>adaboost)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> adaboost <span class="op">==</span> bm.benchmark</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">hasattr</span>(bm.benchmark, <span class="st">"predict"</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> bm.predict(X).shape <span class="op">==</span> y.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Below we compare the benchmark (set above manually to be the adaboost algorithm) with two other candidate models: a Gaussian process and a linear Support Vector Machine (SVM).</p>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.gaussian_process <span class="im">import</span> GaussianProcessRegressor</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> LinearSVR</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>gauss_reg <span class="op">=</span> GaussianProcessRegressor().fit(X, y)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>svm_reg <span class="op">=</span> LinearSVR().fit(X, y)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>bm.compare(X, y, candidates<span class="op">=</span>[gauss_reg, svm_reg])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Benchmark updated!
New benchmark:
Pipeline(steps=[('candidate_estimator', LinearSVR())])</code></pre>
</div>
</div>
<p>Note that when the benchmark object finds a model that performs better than it does, the user is informed that the benchmark is updated and the new benchmark model is shown. This only happens when the argument <code>update_benchmark</code> is set to True (as default).</p>
<p>Below we can see by how much it outperformed the other candidates, including the previous benchmark model and an ensemble of the previous benchmark and all the candidates. It is also a good opportunity to see how stable the performance of each model was, as judged by the standard deviation of the scores across the validation folds.</p>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(bm.benchmark.cv_results_)[[<span class="st">'params'</span>, <span class="st">'mean_test_score'</span>, <span class="st">'std_test_score'</span>, <span class="st">'rank_test_score'</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">params</th>
<th data-quarto-table-cell-role="th">mean_test_score</th>
<th data-quarto-table-cell-role="th">std_test_score</th>
<th data-quarto-table-cell-role="th">rank_test_score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>{'candidate_estimator': (DecisionTreeRegressor...</td>
<td>0.397447</td>
<td>0.218386</td>
<td>2</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>{'candidate_estimator': GaussianProcessRegress...</td>
<td>-0.110557</td>
<td>0.095238</td>
<td>4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>{'candidate_estimator': LinearSVR(), 'candidat...</td>
<td>0.514280</td>
<td>0.109810</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>{'candidate_estimator': VotingRegressor(estima...</td>
<td>0.353772</td>
<td>0.129073</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
</section>
</section>
<section id="general-comments-on-benchmarks" class="level1">
<h1>General comments on benchmarks</h1>
<section id="scoring" class="level2">
<h2 class="anchored" data-anchor-id="scoring">Scoring</h2>
<p><code>ClassificationBenchmark</code> and <code>RegressionBenchmark</code> use the default scoring method for comparing model alternatives, both during estimation of the benchmark model and when comparing this benchmark with candidate models. Users are encouraged to consider if another scoring method is more suitable for their use case. More information on available scoring methods that are compatible with <code>gingado</code> Benchmark objects can be found <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">here</a>.</p>
</section>
<section id="data-split" class="level2">
<h2 class="anchored" data-anchor-id="data-split">Data split</h2>
<p><code>gingado</code> benchmarks rely on hyperparameter tuning to discover the benchmark specification that is most likely to perform better with the user data. This tuning in turn depends on a data splitting strategy for the cross-validation. By default, <code>gingado</code> uses <code>StratifiedShuffleSplit</code> (in classification problems) or <code>ShuffleSplit</code> (in regression problems) if the data is not time series and <code>TimeSeriesSplit</code> otherwise.</p>
<p>The user may overrun these defaults either by directly setting the parameter <code>cv</code> or <code>default_cv</code> when instanciating the <code>gingado</code> benchmark class. The difference is that <code>default_cv</code> is only used after <code>gingado</code> checks that the data is not a time series (if a time dimension exists, then <code>TimeSeriesSplit</code> is used).</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_classification()</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>bm_cls <span class="op">=</span> ClassificationBenchmark(cv<span class="op">=</span>TimeSeriesSplit(n_splits<span class="op">=</span><span class="dv">3</span>)).fit(X, y)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> bm_cls.benchmark.n_splits_ <span class="op">==</span> <span class="dv">3</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> make_regression()</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>bm_reg <span class="op">=</span> RegressionBenchmark(default_cv<span class="op">=</span>ShuffleSplit(n_splits<span class="op">=</span><span class="dv">7</span>)).fit(X, y)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> bm_reg.benchmark.n_splits_ <span class="op">==</span> <span class="dv">7</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Please refer to <a href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection">this page</a> for more information on the different <code>Splitter</code> classes available on <code>scikit-learn</code>, and <a href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py">this page</a> for practical advice on how to choose a splitter for data that are not time series. Any one of these objects (or a custom splitter that is compatible with them) can be passed to a <code>Benchmark</code> object.</p>
<p>Users that wish to use specific parameters should include the actual <code>Splitter</code> object as the parameter, as done with the <code>n_splits</code> parameter in the chunk above.</p>
</section>
<section id="custom-benchmarks" class="level2">
<h2 class="anchored" data-anchor-id="custom-benchmarks">Custom benchmarks</h2>
<p><code>gingado</code> provides users with two <code>Benchmark</code> objects out of the box: <code>ClassificationBenchmark</code> and <code>RegressionBenchmark</code>, to be used depending on the task at hand. Both classes derive from a base class <code>ggdBenchmark</code>, which implements methods that facilitate model comparison. Users that want to create a customised benchmark model for themselves have two options:</p>
<ul>
<li><p>the simpler possibility is to train the estimator as usual, and then assign the fitted estimator to a <code>Benchmark</code> object.</p></li>
<li><p>if the user wants more control over the fitting process of estimating the benchmark, they can create a class that subclasses from <code>ggdBenchmark</code> and either implements custom <code>fit</code>, <code>predict</code> and <code>score</code> methods, or also subclasses from <a href="https://scikit-learn.org/stable/modules/generated/sklearn.base.BaseEstimator.html"><code>scikit-learn</code>’s <code>BaseEstimator</code></a>.</p>
<ul>
<li>In any case, if the user wants the benchmark to automatically detect if the data is a time series and also to document the model right after fitting, the <code>fit</code> method should call <code>self._fit</code> on the data. Otherwise, the user can simply implement any consistent logic in fit as the user sees fit (pun intended).</li>
</ul></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>