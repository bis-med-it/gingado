<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Douglas K. G. Araujo">
<meta name="description" content="An illustration with Barro and Lee (1994)">

<title>gingado - Using gingado to understand economic growth</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="gingado - Using gingado to understand economic growth">
<meta property="og:description" content="An illustration with Barro and Lee (1994)">
<meta property="og:image" content="01_BarroLee1994_files/figure-html/cell-6-output-2.png">
<meta property="og:site-name" content="gingado">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">gingado</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-examples" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Examples</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-examples">    
        <li>
    <a class="dropdown-item" href="./barrolee1994.html" rel="" target="">
 <span class="dropdown-text">Economic growth</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./forecast.html" rel="" target="">
 <span class="dropdown-text">Forecasting FX rates</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./machine_controls.html" rel="" target="">
 <span class="dropdown-text">Effects of labour reform</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-reference" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Reference</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-reference">    
        <li>
    <a class="dropdown-item" href="./augmentation.html" rel="" target="">
 <span class="dropdown-text">gingado.augmentation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./datasets.html" rel="" target="">
 <span class="dropdown-text">gingado.datasets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./benchmark.html" rel="" target="">
 <span class="dropdown-text">gingado.benchmark</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./estimators.html" rel="" target="">
 <span class="dropdown-text">gingado.estimators</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./documentation.html" rel="" target="">
 <span class="dropdown-text">gingado.model_documentation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./utils.html" rel="" target="">
 <span class="dropdown-text">gingado.utils</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/bis-med-it/gingado" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.sdmx.io" rel="" target=""><i class="bi bi-house-fill" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#setting-the-stage" id="toc-setting-the-stage" class="nav-link active" data-scroll-target="#setting-the-stage">Setting the stage</a></li>
  <li><a href="#establishing-a-benchmark-model" id="toc-establishing-a-benchmark-model" class="nav-link" data-scroll-target="#establishing-a-benchmark-model">Establishing a benchmark model</a></li>
  <li><a href="#testing-the-conditional-converge-hypothesis" id="toc-testing-the-conditional-converge-hypothesis" class="nav-link" data-scroll-target="#testing-the-conditional-converge-hypothesis">Testing the conditional converge hypothesis</a></li>
  <li><a href="#model-documentation" id="toc-model-documentation" class="nav-link" data-scroll-target="#model-documentation">Model documentation</a></li>
  <li><a href="#trying-out-model-alternatives" id="toc-trying-out-model-alternatives" class="nav-link" data-scroll-target="#trying-out-model-alternatives">Trying out model alternatives</a>
  <ul>
  <li><a href="#first-candidate-a-gradient-boosting-tree" id="toc-first-candidate-a-gradient-boosting-tree" class="nav-link" data-scroll-target="#first-candidate-a-gradient-boosting-tree">First candidate: a gradient boosting tree</a></li>
  <li><a href="#second-candidate-lasso" id="toc-second-candidate-lasso" class="nav-link" data-scroll-target="#second-candidate-lasso">Second candidate: lasso</a></li>
  </ul></li>
  <li><a href="#comparing-the-models-with-the-benchmark" id="toc-comparing-the-models-with-the-benchmark" class="nav-link" data-scroll-target="#comparing-the-models-with-the-benchmark">Comparing the models with the benchmark</a></li>
  <li><a href="#model-documentation-1" id="toc-model-documentation-1" class="nav-link" data-scroll-target="#model-documentation-1">Model documentation</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/bis-med-it/gingado/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Using gingado to understand economic growth</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>

<div>
  <div class="description">
    An illustration with <span class="citation" data-cites="BARRO19941">Barro and Lee (<a href="#ref-BARRO19941" role="doc-biblioref">1994</a>)</span>
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Douglas K. G. Araujo </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<p>This notebook showcases one possible use of <code>gingado</code> by estimating economic growth across countries, using the dataset studied by <span class="citation" data-cites="BARRO19941">Barro and Lee (<a href="#ref-BARRO19941" role="doc-biblioref">1994</a>)</span>. You can run this notebook interactively, by clicking on the appropriate link above.</p>
<p>This dataset has been widely studied in economics. <span class="citation" data-cites="belloni2011inference">Belloni, Chernozhukov, and Hansen (<a href="#ref-belloni2011inference" role="doc-biblioref">2011</a>)</span> and <span class="citation" data-cites="giannone2021illusion">Giannone, Lenza, and Primiceri (<a href="#ref-giannone2021illusion" role="doc-biblioref">2021</a>)</span> are two studies of this dataset that are most related to machine learning.</p>
<p>This notebook will use <code>gingado</code> to compare quickly setup a well-performing machine learning model and use its results as evidence to support the conditional convergence hypothesis; compare different classes of models (and their combination in a single model), and use and document the best performing alternative.</p>
<p>Because the notebook is for pedagogical purposes only, please bear in mind some aspects of the machine learning workflow (such as carefully thinking about the cross-validation strategy) are glossed over in this notebook. Also, only the key academic references are cited; more references can be found in the papers mentioned in this example.</p>
<p>For a more thorough description of <code>gingado</code>, please refer to the package’s <a href="https://github.com/bis-med-it/gingado">website</a> and to the academic <a href="https://www.github.com/dkgaraujo/gingado_comms">material</a> about it.</p>
<section id="setting-the-stage" class="level2">
<h2 class="anchored" data-anchor-id="setting-the-stage">Setting the stage</h2>
<p>We will import packages as the work progresses. This will help highlight the specific steps in the workflow that <code>gingado</code> can be helpful with.</p>
<div class="cell" data-execution_count="1">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The data is available in the <a href="https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA17842">online annex</a> to <span class="citation" data-cites="giannone2021illusion">Giannone, Lenza, and Primiceri (<a href="#ref-giannone2021illusion" role="doc-biblioref">2021</a>)</span>. In that paper, this dataset corresponds to what the authors call “macro2”. The original data, along with more information on the variables, can be found in <a href="http://www2.nber.org/pub/barro.lee/">this NBER website</a>. A very helpful codebook is found <a href="https://github.com/bizmaercq/Do-Poor-Countries-Grow-Faster-than-Rich-Countries/blob/master/data/Codebook.txt">in this repo</a>.</p>
<div class="cell" data-execution_count="2">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gingado.datasets <span class="im">import</span> load_BarroLee_1994</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_BarroLee_1994()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The dataset contains explanatory variables representing per-capita growth between 1960 and 1985, for 90 countries.</p>
<div class="cell" data-execution_count="3">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>X.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>Index(['Unnamed: 0', 'gdpsh465', 'bmp1l', 'freeop', 'freetar', 'h65', 'hm65',
       'hf65', 'p65', 'pm65', 'pf65', 's65', 'sm65', 'sf65', 'fert65',
       'mort65', 'lifee065', 'gpop1', 'fert1', 'mort1', 'invsh41', 'geetot1',
       'geerec1', 'gde1', 'govwb1', 'govsh41', 'gvxdxe41', 'high65', 'highm65',
       'highf65', 'highc65', 'highcm65', 'highcf65', 'human65', 'humanm65',
       'humanf65', 'hyr65', 'hyrm65', 'hyrf65', 'no65', 'nom65', 'nof65',
       'pinstab1', 'pop65', 'worker65', 'pop1565', 'pop6565', 'sec65',
       'secm65', 'secf65', 'secc65', 'seccm65', 'seccf65', 'syr65', 'syrm65',
       'syrf65', 'teapri65', 'teasec65', 'ex1', 'im1', 'xr65', 'tot1'],
      dtype='object')</code></pre>
</div>
</div>
<div class="cell" data-execution_count="4">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>X.head().T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">Unnamed: 0</td>
<td>0.000000</td>
<td>1.000000</td>
<td>2.000000</td>
<td>3.000000</td>
<td>4.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">gdpsh465</td>
<td>6.591674</td>
<td>6.829794</td>
<td>8.895082</td>
<td>7.565275</td>
<td>7.162397</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">bmp1l</td>
<td>0.283700</td>
<td>0.614100</td>
<td>0.000000</td>
<td>0.199700</td>
<td>0.174000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">freeop</td>
<td>0.153491</td>
<td>0.313509</td>
<td>0.204244</td>
<td>0.248714</td>
<td>0.299252</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">freetar</td>
<td>0.043888</td>
<td>0.061827</td>
<td>0.009186</td>
<td>0.036270</td>
<td>0.037367</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">teasec65</td>
<td>17.300000</td>
<td>18.000000</td>
<td>20.700000</td>
<td>22.700000</td>
<td>17.600000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">ex1</td>
<td>0.072900</td>
<td>0.094000</td>
<td>0.174100</td>
<td>0.126500</td>
<td>0.121100</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">im1</td>
<td>0.066700</td>
<td>0.143800</td>
<td>0.175000</td>
<td>0.149600</td>
<td>0.130800</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">xr65</td>
<td>0.348000</td>
<td>0.525000</td>
<td>1.082000</td>
<td>6.625000</td>
<td>2.500000</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">tot1</td>
<td>-0.014727</td>
<td>0.005750</td>
<td>-0.010040</td>
<td>-0.002195</td>
<td>0.003283</td>
</tr>
</tbody>
</table>

<p>62 rows × 5 columns</p>
</div>
</div>
</div>
<p>The outcome variable is represented here:</p>
<div class="cell" data-execution_count="5">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>y.plot.hist(bins<span class="op">=</span><span class="dv">90</span>, title<span class="op">=</span><span class="st">'GDP growth'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>&lt;Axes: title={'center': 'GDP growth'}, ylabel='Frequency'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-6-output-2.png" width="576" height="431"></p>
</div>
</div>
</section>
<section id="establishing-a-benchmark-model" class="level2">
<h2 class="anchored" data-anchor-id="establishing-a-benchmark-model">Establishing a benchmark model</h2>
<p>Generally speaking, it is a good idea to establish a benchmark model at the first stages of development of the machine learning model. <code>gingado</code> offers a class of automatic benchmarks that can be used off-the-shelf depending on the task at hand: <code>RegressionBenchmark</code> and <code>ClassificationBenchmark</code>. It is also good to keep in mind that more advanced users can create their own benchmark on top of a base class provided by <code>gingado</code>: <code>ggdBenchmark</code>.</p>
<p>For this application, since we are interested in running a regression task, we will use <code>RegressionBenchmark</code>:</p>
<div class="cell" data-execution_count="6">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gingado.benchmark <span class="im">import</span> RegressionBenchmark</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>What this object does is the following:</p>
<ul>
<li><p>it creates a random forest</p></li>
<li><p>three different versions of the random forest are trained on the user data</p></li>
<li><p>the version that performs better is chosen as the benchmark</p></li>
<li><p>right after it is trained, the benchmark is documented using <code>gingado</code>’s <code>ModelCard</code> documenter.</p></li>
</ul>
<p>The user can easily change the parameters above. For example, instead of a random forest the user might prefer a neural network as the benchmark. Or, in lieu of the default parameters provided by <code>gingado</code>, users might have their own idea of what could be a reasonable parameter space to search.</p>
<p>Random forests are chosen as the go-to benchmark algorithm because of their reasonably good performance in a wide variety of settings, the fact that they don’t require much data transformation (ie, normalising the data to have zero mean and one standard deviation), and by virtue of their relatively transparency about the importance of each regressor.</p>
<p>The first step is to initialise the benchmark object. At this time, we pass some arguments about how we want it to behave. In this case, we set the verbosity level to produce output related to each alternative considered. Then we fit it to the data.</p>
<div class="cell" data-execution_count="7">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#####</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#####</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>rfr <span class="op">=</span> RandomForestRegressor()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>rfr.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="7">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked=""><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;RandomForestRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor()</pre></div> </div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="8">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>benchmark <span class="op">=</span> RegressionBenchmark(verbose_grid<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>benchmark.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.9s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="8">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RegressionBenchmark(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                    verbose_grid=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RegressionBenchmark<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RegressionBenchmark(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                    verbose_grid=2)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">estimator: RandomForestRegressor</label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(oob_score=True)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RandomForestRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(oob_score=True)</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<p>As we can see above, with a few lines we have trained a random forest on the dataset. In this case, the benchmark was the better of six versions of the random forest, according to the default hyperparameters: 100 and 250 estimators were alternated with models for which the maximum number of regressors analysed by individual trees changesd fom the maximum, a square root and a log of the number of regressors. They were each trained using a 5-fold cross-validation.</p>
<p>Let’s see which one was the best performing in this case, and hence our benchmark model:</p>
<div class="cell" data-execution_count="9">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(benchmark.benchmark.cv_results_).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_fit_time</td>
<td>0.163778</td>
<td>0.416524</td>
<td>0.156408</td>
<td>0.401924</td>
<td>0.357325</td>
<td>0.918653</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">std_fit_time</td>
<td>0.003099</td>
<td>0.03446</td>
<td>0.003776</td>
<td>0.010728</td>
<td>0.005502</td>
<td>0.017598</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_score_time</td>
<td>0.004408</td>
<td>0.010202</td>
<td>0.0049</td>
<td>0.0106</td>
<td>0.004594</td>
<td>0.010897</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">std_score_time</td>
<td>0.000485</td>
<td>0.000872</td>
<td>0.000542</td>
<td>0.000665</td>
<td>0.000494</td>
<td>0.000942</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">param_max_features</td>
<td>sqrt</td>
<td>sqrt</td>
<td>log2</td>
<td>log2</td>
<td>None</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">param_n_estimators</td>
<td>100</td>
<td>250</td>
<td>100</td>
<td>250</td>
<td>100</td>
<td>250</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">params</td>
<td>{'max_features': 'sqrt', 'n_estimators': 100}</td>
<td>{'max_features': 'sqrt', 'n_estimators': 250}</td>
<td>{'max_features': 'log2', 'n_estimators': 100}</td>
<td>{'max_features': 'log2', 'n_estimators': 250}</td>
<td>{'max_features': None, 'n_estimators': 100}</td>
<td>{'max_features': None, 'n_estimators': 250}</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split0_test_score</td>
<td>0.125133</td>
<td>0.074779</td>
<td>-0.024927</td>
<td>0.03332</td>
<td>0.338224</td>
<td>0.347612</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split1_test_score</td>
<td>-0.009071</td>
<td>-0.185941</td>
<td>-0.426723</td>
<td>-0.313894</td>
<td>-0.402183</td>
<td>-0.216237</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split2_test_score</td>
<td>0.115375</td>
<td>0.20975</td>
<td>0.048034</td>
<td>0.174387</td>
<td>0.412444</td>
<td>0.450339</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split3_test_score</td>
<td>0.212205</td>
<td>0.112223</td>
<td>0.140618</td>
<td>0.057973</td>
<td>0.217012</td>
<td>0.320259</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split4_test_score</td>
<td>0.36375</td>
<td>0.405129</td>
<td>0.310336</td>
<td>0.334398</td>
<td>0.360509</td>
<td>0.369756</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split5_test_score</td>
<td>0.160114</td>
<td>-0.186722</td>
<td>-0.231316</td>
<td>-0.063394</td>
<td>-1.478066</td>
<td>-0.850605</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split6_test_score</td>
<td>-0.300547</td>
<td>-0.48486</td>
<td>-0.154971</td>
<td>-0.336687</td>
<td>-1.823058</td>
<td>-1.358673</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split7_test_score</td>
<td>0.068459</td>
<td>0.127652</td>
<td>-0.00621</td>
<td>-0.067654</td>
<td>0.403121</td>
<td>0.414887</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split8_test_score</td>
<td>0.157384</td>
<td>-0.074184</td>
<td>0.02082</td>
<td>-0.144453</td>
<td>-0.002687</td>
<td>-0.300831</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split9_test_score</td>
<td>0.219091</td>
<td>0.158893</td>
<td>0.202475</td>
<td>0.215259</td>
<td>0.280196</td>
<td>0.288026</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean_test_score</td>
<td>0.111189</td>
<td>0.015672</td>
<td>-0.012186</td>
<td>-0.011075</td>
<td>-0.169449</td>
<td>-0.053547</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std_test_score</td>
<td>0.166189</td>
<td>0.239881</td>
<td>0.204599</td>
<td>0.208126</td>
<td>0.780092</td>
<td>0.59128</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">rank_test_score</td>
<td>1</td>
<td>2</td>
<td>4</td>
<td>3</td>
<td>6</td>
<td>5</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The values above are calculated with <span class="math inline">\(R^2\)</span>, the default scoring function for a random forest from the <code>scikit-learn</code> package. Suppose that instead we would like a benchmark model that is optimised on the maximum error, ie a benchmark that minimises the worst deviation from prediction to ground truth for all the sample. These are the steps that we would take. Note that a more complete list of ready-made scoring parameters and how to create your own function can be found <a href="https://scikit-learn.org/stable/modules/model_evaluation.html#">here</a>.</p>
<div class="cell" data-execution_count="10">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>benchmark_lower_worsterror <span class="op">=</span> RegressionBenchmark(scoring<span class="op">=</span><span class="st">'max_error'</span>, verbose_grid<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>benchmark_lower_worsterror.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.9s</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="10">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</a></style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>RegressionBenchmark(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                    scoring='max_error', verbose_grid=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RegressionBenchmark<span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>RegressionBenchmark(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                    scoring='max_error', verbose_grid=2)</pre></div> </div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">estimator: RandomForestRegressor</label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(oob_score=True)</pre></div> </div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;RandomForestRegressor<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestRegressor.html">?<span>Documentation for RandomForestRegressor</span></a></label><div class="sk-toggleable__content fitted"><pre>RandomForestRegressor(oob_score=True)</pre></div> </div></div></div></div></div></div></div></div></div>
</div>
</div>
<div class="cell" data-execution_count="11">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(benchmark_lower_worsterror.benchmark.cv_results_).T</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">0</th>
<th data-quarto-table-cell-role="th">1</th>
<th data-quarto-table-cell-role="th">2</th>
<th data-quarto-table-cell-role="th">3</th>
<th data-quarto-table-cell-role="th">4</th>
<th data-quarto-table-cell-role="th">5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_fit_time</td>
<td>0.15971</td>
<td>0.403323</td>
<td>0.152706</td>
<td>0.38912</td>
<td>0.361219</td>
<td>0.90905</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">std_fit_time</td>
<td>0.003285</td>
<td>0.007874</td>
<td>0.002864</td>
<td>0.00635</td>
<td>0.006984</td>
<td>0.023647</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">mean_score_time</td>
<td>0.005303</td>
<td>0.009999</td>
<td>0.0044</td>
<td>0.010901</td>
<td>0.0046</td>
<td>0.010502</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">std_score_time</td>
<td>0.001003</td>
<td>0.000447</td>
<td>0.000664</td>
<td>0.001812</td>
<td>0.000491</td>
<td>0.001204</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">param_max_features</td>
<td>sqrt</td>
<td>sqrt</td>
<td>log2</td>
<td>log2</td>
<td>None</td>
<td>None</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">param_n_estimators</td>
<td>100</td>
<td>250</td>
<td>100</td>
<td>250</td>
<td>100</td>
<td>250</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">params</td>
<td>{'max_features': 'sqrt', 'n_estimators': 100}</td>
<td>{'max_features': 'sqrt', 'n_estimators': 250}</td>
<td>{'max_features': 'log2', 'n_estimators': 100}</td>
<td>{'max_features': 'log2', 'n_estimators': 250}</td>
<td>{'max_features': None, 'n_estimators': 100}</td>
<td>{'max_features': None, 'n_estimators': 250}</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split0_test_score</td>
<td>-0.103235</td>
<td>-0.09774</td>
<td>-0.087245</td>
<td>-0.097594</td>
<td>-0.073086</td>
<td>-0.075141</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split1_test_score</td>
<td>-0.087275</td>
<td>-0.091776</td>
<td>-0.088088</td>
<td>-0.094111</td>
<td>-0.111384</td>
<td>-0.107387</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split2_test_score</td>
<td>-0.122196</td>
<td>-0.120517</td>
<td>-0.116453</td>
<td>-0.123124</td>
<td>-0.117617</td>
<td>-0.117778</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split3_test_score</td>
<td>-0.064369</td>
<td>-0.057022</td>
<td>-0.059418</td>
<td>-0.060488</td>
<td>-0.066795</td>
<td>-0.055791</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split4_test_score</td>
<td>-0.050851</td>
<td>-0.049638</td>
<td>-0.04389</td>
<td>-0.046569</td>
<td>-0.055381</td>
<td>-0.058077</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split5_test_score</td>
<td>-0.127822</td>
<td>-0.121521</td>
<td>-0.118703</td>
<td>-0.125538</td>
<td>-0.117721</td>
<td>-0.119851</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split6_test_score</td>
<td>-0.092334</td>
<td>-0.086957</td>
<td>-0.096306</td>
<td>-0.088426</td>
<td>-0.085814</td>
<td>-0.087153</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split7_test_score</td>
<td>-0.095489</td>
<td>-0.09506</td>
<td>-0.100811</td>
<td>-0.096241</td>
<td>-0.082275</td>
<td>-0.078419</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">split8_test_score</td>
<td>-0.079377</td>
<td>-0.089063</td>
<td>-0.089799</td>
<td>-0.088997</td>
<td>-0.101691</td>
<td>-0.096224</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">split9_test_score</td>
<td>-0.067537</td>
<td>-0.054873</td>
<td>-0.069652</td>
<td>-0.058784</td>
<td>-0.054295</td>
<td>-0.058306</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean_test_score</td>
<td>-0.089049</td>
<td>-0.086417</td>
<td>-0.087036</td>
<td>-0.087987</td>
<td>-0.086606</td>
<td>-0.085413</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">std_test_score</td>
<td>0.023416</td>
<td>0.024178</td>
<td>0.022537</td>
<td>0.024836</td>
<td>0.023206</td>
<td>0.02313</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">rank_test_score</td>
<td>6</td>
<td>2</td>
<td>4</td>
<td>5</td>
<td>3</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Now we even have two benchmark models.</p>
<p>We could further tweak and adjust them, but one of the ideas behind having a benchmark is that it is simple and easy to set up.</p>
<p>Let’s retain only the first benchmark, for simplicity, and now look at the predictions, comparing them to the original growth values.</p>
<div class="cell" data-execution_count="12">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> benchmark.predict(X)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>,</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>         grid<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>         title<span class="op">=</span><span class="st">'Actual and predicted outcome'</span>,</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>         xlabel<span class="op">=</span><span class="st">'actual GDP growth'</span>,</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>         ylabel<span class="op">=</span><span class="st">'predicted GDP growth'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>&lt;Axes: title={'center': 'Actual and predicted outcome'}, xlabel='actual GDP growth', ylabel='predicted GDP growth'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-13-output-2.png" width="617" height="449"></p>
</div>
</div>
<p>And now a histogram of the benchmark’s errors:</p>
<div class="cell" data-execution_count="13">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>, title<span class="op">=</span><span class="st">'Residual'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>&lt;Axes: title={'center': 'Residual'}, ylabel='Frequency'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-14-output-2.png" width="585" height="431"></p>
</div>
</div>
<p>Since the benchmark is a random forest model, we can see what are the most important regressors, measured as the average reduction in impurity across the trees in the random forest that actually use that particular regressor. They are scaled so that the sum for all features is one. Higher importance amounts indicate that that particular regressor is a more important contributor to the final prediction.</p>
<div class="cell" data-execution_count="14">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>regressor_importance <span class="op">=</span> pd.DataFrame(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    benchmark.benchmark.best_estimator_.feature_importances_, </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>X.columns, </span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"Importance"</span>]</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>regressor_importance.sort_values(by<span class="op">=</span><span class="st">"Importance"</span>, ascending<span class="op">=</span><span class="va">False</span>) <span class="op">\</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    .plot.bar(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span>), title<span class="op">=</span><span class="st">'Regressor importance'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>&lt;Axes: title={'center': 'Regressor importance'}&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-15-output-2.png" width="1546" height="721"></p>
</div>
</div>
<p>From the graph above, we can see that the regressor <code>bmp1l</code> (black-market premium on foreign exchange) predominates. Interestingly, <span class="citation" data-cites="belloni2011inference">Belloni, Chernozhukov, and Hansen (<a href="#ref-belloni2011inference" role="doc-biblioref">2011</a>)</span> using squared-root lasso also find this regressor to be important.</p>
</section>
<section id="testing-the-conditional-converge-hypothesis" class="level2">
<h2 class="anchored" data-anchor-id="testing-the-conditional-converge-hypothesis">Testing the conditional converge hypothesis</h2>
<p>Now we can leverage our automatic benchmark model to test the conditional converge hypothesis - ie, the preposition that countries with lower starting GDP tend to grow faster than other <em>comparable</em> countries. In other words, this hypothesis predicts that when GDP growth is regressed on the level of past GDP and on an adequate set of covariates <span class="math inline">\(X\)</span>, the coefficient on past GDP levels are negative.</p>
<p>Since we have the results for the importance of each regressor in separating countries by their growth result, we can compare the estimated coefficient for GDP levels in regressions that include different regressors in the vector <span class="math inline">\(X\)</span>. To maintain this example a simple exercise, the following three models are estimated:</p>
<ul>
<li><span class="math inline">\(X\)</span> contains the five most important regressors, as estimated by the benchmark model (see the graph above)</li>
<li><span class="math inline">\(X\)</span> contains the five <em>least</em> important regressors, from the same estimation as above</li>
<li><span class="math inline">\(X\)</span> is the empty set - in other words, this is a simple equation on GDP growth on GDP levels</li>
</ul>
<p>A result that would be consistent with the <em>conditionality</em> of the conditional convergence hypothesis is the first equation resulting in a negative coefficient for starting GDP, while the following two equations may not necessarily be successful in identifying a negative coefficient. This is because the least important regressors are not likely to have sufficient predictive power to separate countries into comparable groups.</p>
<p>The five more and less important regressors are:</p>
<div class="cell" data-execution_count="15">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>top_five <span class="op">=</span> regressor_importance.sort_values(by<span class="op">=</span><span class="st">"Importance"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>bottom_five <span class="op">=</span> regressor_importance.sort_values(by<span class="op">=</span><span class="st">"Importance"</span>, ascending<span class="op">=</span><span class="va">True</span>).head(<span class="dv">5</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>top_five, bottom_five</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(          Importance
 pop6565     0.051582
 bmp1l       0.046167
 freetar     0.031713
 teasec65    0.030280
 ex1         0.029907,
          Importance
 no65       0.004085
 sf65       0.005126
 seccf65    0.005221
 pf65       0.005759
 syrf65     0.006241)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="16">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="17">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>gdp_level <span class="op">=</span> <span class="st">'gdpsh465'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="18">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>X_topfive <span class="op">=</span> X[[gdp_level] <span class="op">+</span> <span class="bu">list</span>(top_five.index)]</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>X_topfive <span class="op">=</span> sm.add_constant(X_topfive)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>X_topfive.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">const</th>
<th data-quarto-table-cell-role="th">gdpsh465</th>
<th data-quarto-table-cell-role="th">pop6565</th>
<th data-quarto-table-cell-role="th">bmp1l</th>
<th data-quarto-table-cell-role="th">freetar</th>
<th data-quarto-table-cell-role="th">teasec65</th>
<th data-quarto-table-cell-role="th">ex1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.591674</td>
<td>0.027591</td>
<td>0.2837</td>
<td>0.043888</td>
<td>17.3</td>
<td>0.0729</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>6.829794</td>
<td>0.035637</td>
<td>0.6141</td>
<td>0.061827</td>
<td>18.0</td>
<td>0.0940</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>8.895082</td>
<td>0.076685</td>
<td>0.0000</td>
<td>0.009186</td>
<td>20.7</td>
<td>0.1741</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.0</td>
<td>7.565275</td>
<td>0.031039</td>
<td>0.1997</td>
<td>0.036270</td>
<td>22.7</td>
<td>0.1265</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1.0</td>
<td>7.162397</td>
<td>0.026281</td>
<td>0.1740</td>
<td>0.037367</td>
<td>17.6</td>
<td>0.1211</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="19">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>X_bottomfive <span class="op">=</span> X[[gdp_level] <span class="op">+</span> <span class="bu">list</span>(bottom_five.index)]</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>X_bottomfive <span class="op">=</span> sm.add_constant(X_bottomfive)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>X_bottomfive.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="19">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">const</th>
<th data-quarto-table-cell-role="th">gdpsh465</th>
<th data-quarto-table-cell-role="th">no65</th>
<th data-quarto-table-cell-role="th">sf65</th>
<th data-quarto-table-cell-role="th">seccf65</th>
<th data-quarto-table-cell-role="th">pf65</th>
<th data-quarto-table-cell-role="th">syrf65</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.591674</td>
<td>89.46</td>
<td>0.02</td>
<td>0.04</td>
<td>0.21</td>
<td>0.010</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>6.829794</td>
<td>89.10</td>
<td>0.09</td>
<td>0.64</td>
<td>0.65</td>
<td>0.067</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>8.895082</td>
<td>1.40</td>
<td>0.51</td>
<td>18.14</td>
<td>1.00</td>
<td>2.667</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.0</td>
<td>7.565275</td>
<td>20.60</td>
<td>0.31</td>
<td>2.63</td>
<td>1.00</td>
<td>0.424</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1.0</td>
<td>7.162397</td>
<td>58.73</td>
<td>0.13</td>
<td>2.11</td>
<td>0.81</td>
<td>0.229</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="20">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>X_onlyGDPlevel <span class="op">=</span> sm.add_constant(X[gdp_level])</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>X_onlyGDPlevel.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">const</th>
<th data-quarto-table-cell-role="th">gdpsh465</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>1.0</td>
<td>6.591674</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1.0</td>
<td>6.829794</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1.0</td>
<td>8.895082</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>1.0</td>
<td>7.565275</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>1.0</td>
<td>7.162397</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell" data-execution_count="21">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    topfive <span class="op">=</span> sm.OLS(y, X_topfive).fit(),</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    bottomfive <span class="op">=</span> sm.OLS(y, X_bottomfive).fit(),</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    onlyGDPlevel <span class="op">=</span> sm.OLS(y, X_onlyGDPlevel).fit()</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="22">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> pd.DataFrame({name: model.conf_int().loc[gdp_level] <span class="cf">for</span> name, model <span class="kw">in</span> models.items()})</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>coefs.loc[<span class="fl">0.5</span>] <span class="op">=</span> [model.params[gdp_level] <span class="cf">for</span> _, model <span class="kw">in</span> models.items()]</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> coefs.sort_index().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>coefs.index <span class="op">=</span> [<span class="st">'[0.025'</span>, <span class="st">'coef on GDP levels'</span>, <span class="st">'0.975]'</span>]</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>coefs</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="22">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">topfive</th>
<th data-quarto-table-cell-role="th">bottomfive</th>
<th data-quarto-table-cell-role="th">onlyGDPlevel</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">[0.025</td>
<td>-0.044210</td>
<td>-0.037627</td>
<td>-0.010810</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">coef on GDP levels</td>
<td>-0.025085</td>
<td>-0.012318</td>
<td>0.001317</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">0.975]</td>
<td>-0.005961</td>
<td>0.012990</td>
<td>0.013444</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The equation using the top five regressors in explanatory power yielded a coefficient that is statistically speaking negative under the usual confidence interval levels. In contrast, the regression using the bottom five regressors failed to maintain that level of statistical significance (although the coefficient point estimate was still negative). And finally the regression on GDP level solely resulted, as in the past literature, on a point estimate that is also statistically not different than zero.</p>
<p>These results above offer a different way to add evidence to the conditional convergence hypothesis. In particular, with the help of <code>gingado</code>’s <code>RegressionBenchmark</code> model, it is possible to identify which covariates can meaningfully serve as covariates in a growth equation from those that cannot. This is important because if the covariate selection for some reason included only variables with little explanatory power instead of the most relevant ones, an economist might erroneously reach a different conclusion.</p>
</section>
<section id="model-documentation" class="level2">
<h2 class="anchored" data-anchor-id="model-documentation">Model documentation</h2>
<p>Importantly for model documentation, the benchmark already has some baseline documentation set up. If the user wishes, they can use that as a basis to document their model. Note that the output is in a raw format that is suitable for machine reading and writing. Intermediary and advanced users may wish to use that format to construct personalised forms, documents, etc.</p>
<div class="cell" data-execution_count="23">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.show_json()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>{'model_details': {'developer': 'Person or organisation developing the model',
  'datetime': '2024-02-27 08:56:06 ',
  'version': 'Model version',
  'type': 'Model type',
  'info': {'_estimator_type': 'regressor',
   'best_estimator_': RandomForestRegressor(max_features='sqrt', oob_score=True),
   'best_index_': 0,
   'best_params_': {'max_features': 'sqrt', 'n_estimators': 100},
   'best_score_': 0.11118937747873188,
   'cv_results_': {'mean_fit_time': array([0.16377795, 0.41652365, 0.15640817, 0.40192392, 0.35732486,
           0.91865318]),
    'std_fit_time': array([0.00309857, 0.03446032, 0.00377613, 0.0107279 , 0.00550205,
           0.01759838]),
    'mean_score_time': array([0.0044075 , 0.01020219, 0.0048996 , 0.01060042, 0.0045944 ,
           0.01089656]),
    'std_score_time': array([0.00048533, 0.0008717 , 0.00054155, 0.00066508, 0.00049438,
           0.00094205]),
    'param_max_features': masked_array(data=['sqrt', 'sqrt', 'log2', 'log2', None, None],
                 mask=[False, False, False, False, False, False],
           fill_value='?',
                dtype=object),
    'param_n_estimators': masked_array(data=[100, 250, 100, 250, 100, 250],
                 mask=[False, False, False, False, False, False],
           fill_value='?',
                dtype=object),
    'params': [{'max_features': 'sqrt', 'n_estimators': 100},
     {'max_features': 'sqrt', 'n_estimators': 250},
     {'max_features': 'log2', 'n_estimators': 100},
     {'max_features': 'log2', 'n_estimators': 250},
     {'max_features': None, 'n_estimators': 100},
     {'max_features': None, 'n_estimators': 250}],
    'split0_test_score': array([ 0.12513316,  0.07477857, -0.0249272 ,  0.03332033,  0.33822352,
            0.34761193]),
    'split1_test_score': array([-0.00907123, -0.18594148, -0.42672333, -0.31389368, -0.40218266,
           -0.21623744]),
    'split2_test_score': array([0.1153751 , 0.20975008, 0.04803449, 0.17438704, 0.41244416,
           0.45033912]),
    'split3_test_score': array([0.21220507, 0.11222302, 0.14061849, 0.05797285, 0.21701154,
           0.32025916]),
    'split4_test_score': array([0.36375029, 0.40512908, 0.31033569, 0.33439813, 0.36050901,
           0.36975615]),
    'split5_test_score': array([ 0.16011424, -0.18672163, -0.23131572, -0.06339439, -1.47806613,
           -0.85060539]),
    'split6_test_score': array([-0.30054717, -0.48486002, -0.15497089, -0.33668715, -1.82305801,
           -1.35867328]),
    'split7_test_score': array([ 0.06845935,  0.12765221, -0.00621047, -0.06765449,  0.40312051,
            0.41488671]),
    'split8_test_score': array([ 0.15738397, -0.07418385,  0.02082041, -0.14445327, -0.00268676,
           -0.30083148]),
    'split9_test_score': array([0.21909101, 0.1588931 , 0.20247533, 0.21525865, 0.28019575,
           0.28802643]),
    'mean_test_score': array([ 0.11118938,  0.01567191, -0.01218632, -0.0110746 , -0.16944891,
           -0.05354681]),
    'std_test_score': array([0.16618933, 0.23988085, 0.20459948, 0.20812594, 0.78009171,
           0.59128025]),
    'rank_test_score': array([1, 2, 4, 3, 6, 5])},
   'multimetric_': False,
   'n_features_in_': 62,
   'n_splits_': 10,
   'refit_time_': 0.1650092601776123,
   'scorer_': &lt;sklearn.metrics._scorer._PassthroughScorer at 0x251de79c760&gt;},
  'paper': 'Paper or other resource for more information',
  'citation': 'Citation details',
  'license': 'License',
  'contact': 'Where to send questions or comments about the model'},
 'intended_use': {'primary_uses': 'Primary intended uses',
  'primary_users': 'Primary intended users',
  'out_of_scope': 'Out-of-scope use cases'},
 'factors': {'relevant': 'Relevant factors',
  'evaluation': 'Evaluation factors'},
 'metrics': {'performance_measures': 'Model performance measures',
  'thresholds': 'Decision thresholds',
  'variation_approaches': 'Variation approaches'},
 'evaluation_data': {'datasets': 'Datasets',
  'motivation': 'Motivation',
  'preprocessing': 'Preprocessing'},
 'training_data': {'training_data': 'Information on training data'},
 'quant_analyses': {'unitary': 'Unitary results',
  'intersectional': 'Intersectional results'},
 'ethical_considerations': {'sensitive_data': 'Does the model use any sensitive data (e.g., protected classes)?',
  'human_life': 'Is the model intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?',
  'mitigations': 'What risk mitigation strategies were used during model development?',
  'risks_and_harms': 'What risks may be present in model usage? Try to identify the potential recipients,likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown',
  'use_cases': 'Are there any known model use cases that are especially fraught?',
  'additional_information': 'If possible, this section should also include any additional ethical considerations that went into model development, for example, review by an external board, or testing with a specific community.'},
 'caveats_recommendations': {'caveats': 'For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?',
  'recommendations': 'Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?'}}</code></pre>
</div>
</div>
<p>Since there is some information in the model documentation that was automatically added, we might want to concentrate on the fields in the model card that are yet to be answered. Actually, this is the purpose of <code>gingado</code>’s automatic documentation: to afford users more time so they can invest, if they want, on model documentation.</p>
<div class="cell" data-execution_count="24">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.open_questions()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>['model_details__developer',
 'model_details__version',
 'model_details__type',
 'model_details__paper',
 'model_details__citation',
 'model_details__license',
 'model_details__contact',
 'intended_use__primary_uses',
 'intended_use__primary_users',
 'intended_use__out_of_scope',
 'factors__relevant',
 'factors__evaluation',
 'metrics__performance_measures',
 'metrics__thresholds',
 'metrics__variation_approaches',
 'evaluation_data__datasets',
 'evaluation_data__motivation',
 'evaluation_data__preprocessing',
 'training_data__training_data',
 'quant_analyses__unitary',
 'quant_analyses__intersectional',
 'ethical_considerations__sensitive_data',
 'ethical_considerations__human_life',
 'ethical_considerations__mitigations',
 'ethical_considerations__risks_and_harms',
 'ethical_considerations__use_cases',
 'ethical_considerations__additional_information',
 'caveats_recommendations__caveats',
 'caveats_recommendations__recommendations']</code></pre>
</div>
</div>
<p>Let’s fill some information:</p>
<div class="cell" data-execution_count="25">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.fill_info({</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'intended_use'</span>: {</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">'primary_uses'</span>: <span class="st">'This model is trained for pedagogical uses only.'</span>,</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">'primary_users'</span>: <span class="st">'Everyone is welcome to follow the description showing the development of this benchmark.'</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Note the format, based on a Python dictionary. In particular, the <code>open_questions</code> method results include keys divided by double underscores. As seen above, these should be interpreted as different levels of the documentation template, leading to a nested dictionary.</p>
<p>Now when we confirm that the questions answered above are no longer “open questions”:</p>
<div class="cell" data-execution_count="26">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.open_questions()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>['model_details__developer',
 'model_details__version',
 'model_details__type',
 'model_details__paper',
 'model_details__citation',
 'model_details__license',
 'model_details__contact',
 'intended_use__out_of_scope',
 'factors__relevant',
 'factors__evaluation',
 'metrics__performance_measures',
 'metrics__thresholds',
 'metrics__variation_approaches',
 'evaluation_data__datasets',
 'evaluation_data__motivation',
 'evaluation_data__preprocessing',
 'training_data__training_data',
 'quant_analyses__unitary',
 'quant_analyses__intersectional',
 'ethical_considerations__sensitive_data',
 'ethical_considerations__human_life',
 'ethical_considerations__mitigations',
 'ethical_considerations__risks_and_harms',
 'ethical_considerations__use_cases',
 'ethical_considerations__additional_information',
 'caveats_recommendations__caveats',
 'caveats_recommendations__recommendations']</code></pre>
</div>
</div>
<p>If we want, at any time we can save the documentation to a local JSON file, as well as read another document.</p>
</section>
<section id="trying-out-model-alternatives" class="level2">
<h2 class="anchored" data-anchor-id="trying-out-model-alternatives">Trying out model alternatives</h2>
<p>The benchmark model may be enough for some analyses, or maybe the user is interested in using the benchmark to explore the data and have an understanding of the importance of each regressor, to concentrate their work on data that can be meaningful for their purposes. But oftentimes a user will want to seek a machine learning model that performs as well as possible.</p>
<p>For users that want to manually create other models, <code>gingado</code> allows the possibility of comparing them with the benchmark. If the user model is better, it becomes the new benchmark!</p>
<p>For the following analyses, we will use K-fold as cross-validation, with 5 splits of the sample.</p>
<section id="first-candidate-a-gradient-boosting-tree" class="level3">
<h3 class="anchored" data-anchor-id="first-candidate-a-gradient-boosting-tree">First candidate: a gradient boosting tree</h3>
<div class="cell" data-execution_count="27">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="28">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.25</span>],</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">9</span>]</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>reg_gradbooster <span class="op">=</span> GradientBoostingRegressor()</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>gradboosterg_grid <span class="op">=</span> GridSearchCV(</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    reg_gradbooster,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>).fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 9 candidates, totalling 45 fits</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> gradboosterg_grid.predict(X)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>, grid<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>&lt;Axes: xlabel='y', ylabel='y_pred'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-30-output-2.png" width="608" height="429"></p>
</div>
</div>
<div class="cell" data-execution_count="30">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>&lt;Axes: ylabel='Frequency'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-31-output-2.png" width="585" height="411"></p>
</div>
</div>
</section>
<section id="second-candidate-lasso" class="level3">
<h3 class="anchored" data-anchor-id="second-candidate-lasso">Second candidate: lasso</h3>
<div class="cell" data-execution_count="31">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="32">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'alpha'</span>: [<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.25</span>],</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>reg_lasso <span class="op">=</span> Lasso(fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>lasso_grid <span class="op">=</span> GridSearchCV(</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    reg_lasso,</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>).fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 3 candidates, totalling 15 fits</code></pre>
</div>
</div>
<div class="cell" data-execution_count="33">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lasso_grid.predict(X)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>, grid<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>&lt;Axes: xlabel='y', ylabel='y_pred'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-34-output-2.png" width="597" height="429"></p>
</div>
</div>
<div class="cell" data-execution_count="34">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>&lt;Axes: ylabel='Frequency'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-35-output-2.png" width="587" height="411"></p>
</div>
</div>
</section>
</section>
<section id="comparing-the-models-with-the-benchmark" class="level2">
<h2 class="anchored" data-anchor-id="comparing-the-models-with-the-benchmark">Comparing the models with the benchmark</h2>
<p><code>gingado</code> allows users to compare different candidate models with the existing benchmark in a very simple way: using the <code>compare</code> method.</p>
<div class="cell" data-execution_count="35">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>candidates <span class="op">=</span> [gradboosterg_grid, lasso_grid]</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>benchmark.compare(X, y, candidates)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 10 folds for each of 4 candidates, totalling 40 fits
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  24.6s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.4s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.0s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.5s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.4s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.8s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.1s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  24.0s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.1s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.4s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.0s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END candidate_estimator=GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
             estimator=RandomForestRegressor(oob_score=True),
             param_grid={'max_features': ['sqrt', 'log2', None],
                         'n_estimators': [100, 250]},
             verbose=2), candidate_estimator__cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None), candidate_estimator__error_score=nan, candidate_estimator__estimator=RandomForestRegressor(oob_score=True), candidate_estimator__estimator__bootstrap=True, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=squared_error, candidate_estimator__estimator__max_depth=None, candidate_estimator__estimator__max_features=1.0, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__max_samples=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__monotonic_cst=None, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_jobs=None, candidate_estimator__estimator__oob_score=True, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=None, candidate_estimator__param_grid={'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=  23.3s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.1s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.4s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.3s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.4s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.0s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.4s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.1s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.4s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.1s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
[CV] END candidate_estimator=GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
             param_grid={'learning_rate': [0.01, 0.1, 0.25],
                         'max_depth': [3, 6, 9]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=GradientBoostingRegressor(), candidate_estimator__estimator__alpha=0.9, candidate_estimator__estimator__ccp_alpha=0.0, candidate_estimator__estimator__criterion=friedman_mse, candidate_estimator__estimator__init=None, candidate_estimator__estimator__learning_rate=0.1, candidate_estimator__estimator__loss=squared_error, candidate_estimator__estimator__max_depth=3, candidate_estimator__estimator__max_features=None, candidate_estimator__estimator__max_leaf_nodes=None, candidate_estimator__estimator__min_impurity_decrease=0.0, candidate_estimator__estimator__min_samples_leaf=1, candidate_estimator__estimator__min_samples_split=2, candidate_estimator__estimator__min_weight_fraction_leaf=0.0, candidate_estimator__estimator__n_estimators=100, candidate_estimator__estimator__n_iter_no_change=None, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__subsample=1.0, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__validation_fraction=0.1, candidate_estimator__estimator__verbose=0, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   3.3s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
             verbose=2), candidate_estimator__cv=None, candidate_estimator__error_score=nan, candidate_estimator__estimator=Lasso(), candidate_estimator__estimator__alpha=1.0, candidate_estimator__estimator__copy_X=True, candidate_estimator__estimator__fit_intercept=True, candidate_estimator__estimator__max_iter=1000, candidate_estimator__estimator__positive=False, candidate_estimator__estimator__precompute=False, candidate_estimator__estimator__random_state=None, candidate_estimator__estimator__selection=cyclic, candidate_estimator__estimator__tol=0.0001, candidate_estimator__estimator__warm_start=False, candidate_estimator__n_jobs=-1, candidate_estimator__param_grid={'alpha': [0.5, 1, 1.25]}, candidate_estimator__pre_dispatch=2*n_jobs, candidate_estimator__refit=True, candidate_estimator__return_train_score=False, candidate_estimator__scoring=None, candidate_estimator__verbose=2; total time=   0.0s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.4s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.9s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.7s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.8s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.4s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.7s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  27.0s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  27.1s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.7s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.4s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.4s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  27.0s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=100; total time=   0.2s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.7s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
[CV] END candidate_estimator=VotingRegressor(estimators=[('candidate_1',
                             GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                          estimator=RandomForestRegressor(oob_score=True),
                                          param_grid={'max_features': ['sqrt',
                                                                       'log2',
                                                                       None],
                                                      'n_estimators': [100,
                                                                       250]},
                                          verbose=2)),
                            ('candidate_2',
                             GridSearchCV(estimator=GradientBoostingRegressor(),
                                          n_jobs=-1,
                                          param_grid={'learning_rate': [0.01,
                                                                        0.1,
                                                                        0.25],
                                                      'max_depth': [3, 6, 9]},
                                          verbose=2)),
                            ('candidate_3',
                             GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                          param_grid={'alpha': [0.5, 1, 1.25]},
                                          verbose=2))]); total time=  26.2s
Fitting 10 folds for each of 6 candidates, totalling 60 fits
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=100; total time=   0.1s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=sqrt, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=100; total time=   0.1s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=log2, n_estimators=250; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=100; total time=   0.3s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
[CV] END ................max_features=None, n_estimators=250; total time=   0.8s
Fitting 5 folds for each of 9 candidates, totalling 45 fits
Fitting 5 folds for each of 3 candidates, totalling 15 fits
Benchmark updated!
New benchmark:
Pipeline(steps=[('candidate_estimator',
                 VotingRegressor(estimators=[('candidate_1',
                                              GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                                           estimator=RandomForestRegressor(oob_score=True),
                                                           param_grid={'max_features': ['sqrt',
                                                                                        'log2',
                                                                                        None],
                                                                       'n_estimators': [100,
                                                                                        250]},
                                                           verbose=2)),
                                             ('candidate_2',
                                              GridSearchCV(estimator=GradientBoostingRegressor(),
                                                           n_jobs=-1,
                                                           param_grid={'learning_rate': [0.01,
                                                                                         0.1,
                                                                                         0.25],
                                                                       'max_depth': [3,
                                                                                     6,
                                                                                     9]},
                                                           verbose=2)),
                                             ('candidate_3',
                                              GridSearchCV(estimator=Lasso(),
                                                           n_jobs=-1,
                                                           param_grid={'alpha': [0.5,
                                                                                 1,
                                                                                 1.25]},
                                                           verbose=2))]))])</code></pre>
</div>
</div>
<p>The output above clearly indicates that after evaluating the models - and their ensemble together with the existing benchmark - at least one of them was better than the current benchmark. Therefore, it will now be the new benchmark.</p>
<div class="cell" data-execution_count="36">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> benchmark.predict(X)</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>, grid<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>&lt;Axes: xlabel='y', ylabel='y_pred'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-37-output-2.png" width="597" height="429"></p>
</div>
</div>
<div class="cell" data-execution_count="37">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>&lt;Axes: ylabel='Frequency'&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="01_BarroLee1994_files/figure-html/cell-38-output-2.png" width="591" height="411"></p>
</div>
</div>
</section>
<section id="model-documentation-1" class="level2">
<h2 class="anchored" data-anchor-id="model-documentation-1">Model documentation</h2>
<p>After this process, we can now see how the model documentation was updated automatically:</p>
<div class="cell" data-execution_count="38">
<details open="">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.show_json()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>{'model_details': {'developer': 'Person or organisation developing the model',
  'datetime': '2024-02-27 09:06:12 ',
  'version': 'Model version',
  'type': 'Model type',
  'info': {'_estimator_type': 'regressor',
   'best_estimator_': Pipeline(steps=[('candidate_estimator',
                    VotingRegressor(estimators=[('candidate_1',
                                                 GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                                              estimator=RandomForestRegressor(oob_score=True),
                                                              param_grid={'max_features': ['sqrt',
                                                                                           'log2',
                                                                                           None],
                                                                          'n_estimators': [100,
                                                                                           250]},
                                                              verbose=2)),
                                                ('candidate_2',
                                                 GridSearchCV(estimator=GradientBoostingRegressor(),
                                                              n_jobs=-1,
                                                              param_grid={'learning_rate': [0.01,
                                                                                            0.1,
                                                                                            0.25],
                                                                          'max_depth': [3,
                                                                                        6,
                                                                                        9]},
                                                              verbose=2)),
                                                ('candidate_3',
                                                 GridSearchCV(estimator=Lasso(),
                                                              n_jobs=-1,
                                                              param_grid={'alpha': [0.5,
                                                                                    1,
                                                                                    1.25]},
                                                              verbose=2))]))]),
   'best_index_': 3,
   'best_params_': {'candidate_estimator': VotingRegressor(estimators=[('candidate_1',
                                 GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                              estimator=RandomForestRegressor(oob_score=True),
                                              param_grid={'max_features': ['sqrt',
                                                                           'log2',
                                                                           None],
                                                          'n_estimators': [100,
                                                                           250]},
                                              verbose=2)),
                                ('candidate_2',
                                 GridSearchCV(estimator=GradientBoostingRegressor(),
                                              n_jobs=-1,
                                              param_grid={'learning_rate': [0.01,
                                                                            0.1,
                                                                            0.25],
                                                          'max_depth': [3, 6, 9]},
                                              verbose=2)),
                                ('candidate_3',
                                 GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                              param_grid={'alpha': [0.5, 1, 1.25]},
                                              verbose=2))])},
   'best_score_': 0.07941930227542426,
   'cv_results_': {'mean_fit_time': array([23.60948877,  3.34307327,  0.05800555, 26.85539942]),
    'std_fit_time': array([0.44619918, 0.14330811, 0.00523631, 0.2679792 ]),
    'mean_score_time': array([0.00999823, 0.002302  , 0.00189459, 0.01060665]),
    'std_score_time': array([0.00316378, 0.00064011, 0.00029907, 0.00242532]),
    'param_candidate_estimator': masked_array(data=[GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                    estimator=RandomForestRegressor(oob_score=True),
                                    param_grid={'max_features': ['sqrt', 'log2', None],
                                                'n_estimators': [100, 250]},
                                    verbose=2)                                                                       ,
                       GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
                                    param_grid={'learning_rate': [0.01, 0.1, 0.25],
                                                'max_depth': [3, 6, 9]},
                                    verbose=2)                                       ,
                       GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
                                    verbose=2)                                                         ,
                       VotingRegressor(estimators=[('candidate_1',
                                                    GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                                                 estimator=RandomForestRegressor(oob_score=True),
                                                                 param_grid={'max_features': ['sqrt',
                                                                                              'log2',
                                                                                              None],
                                                                             'n_estimators': [100,
                                                                                              250]},
                                                                 verbose=2)),
                                                   ('candidate_2',
                                                    GridSearchCV(estimator=GradientBoostingRegressor(),
                                                                 n_jobs=-1,
                                                                 param_grid={'learning_rate': [0.01,
                                                                                               0.1,
                                                                                               0.25],
                                                                             'max_depth': [3, 6, 9]},
                                                                 verbose=2)),
                                                   ('candidate_3',
                                                    GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                                                 param_grid={'alpha': [0.5, 1, 1.25]},
                                                                 verbose=2))])                                                                    ],
                 mask=[False, False, False, False],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__cv': masked_array(data=[ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                       None, None, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__error_score': masked_array(data=[nan, nan, nan, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator': masked_array(data=[RandomForestRegressor(oob_score=True),
                       GradientBoostingRegressor(), Lasso(), --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__bootstrap': masked_array(data=[True, --, --, --],
                 mask=[False,  True,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__ccp_alpha': masked_array(data=[0.0, 0.0, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__criterion': masked_array(data=['squared_error', 'friedman_mse', --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__max_depth': masked_array(data=[None, 3, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__max_features': masked_array(data=[1.0, None, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__max_leaf_nodes': masked_array(data=[None, None, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__max_samples': masked_array(data=[None, --, --, --],
                 mask=[False,  True,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__min_impurity_decrease': masked_array(data=[0.0, 0.0, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__min_samples_leaf': masked_array(data=[1, 1, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__min_samples_split': masked_array(data=[2, 2, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__min_weight_fraction_leaf': masked_array(data=[0.0, 0.0, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__monotonic_cst': masked_array(data=[None, --, --, --],
                 mask=[False,  True,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__n_estimators': masked_array(data=[100, 100, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__n_jobs': masked_array(data=[None, --, --, --],
                 mask=[False,  True,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__oob_score': masked_array(data=[True, --, --, --],
                 mask=[False,  True,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__random_state': masked_array(data=[None, None, None, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__verbose': masked_array(data=[0, 0, --, --],
                 mask=[False, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__warm_start': masked_array(data=[False, False, False, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__n_jobs': masked_array(data=[None, -1, -1, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__param_grid': masked_array(data=[{'n_estimators': [100, 250], 'max_features': ['sqrt', 'log2', None]},
                       {'learning_rate': [0.01, 0.1, 0.25], 'max_depth': [3, 6, 9]},
                       {'alpha': [0.5, 1, 1.25]}, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__pre_dispatch': masked_array(data=['2*n_jobs', '2*n_jobs', '2*n_jobs', --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__refit': masked_array(data=[True, True, True, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__return_train_score': masked_array(data=[False, False, False, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__scoring': masked_array(data=[None, None, None, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__verbose': masked_array(data=[2, 2, 2, --],
                 mask=[False, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__alpha': masked_array(data=[--, 0.9, 1.0, --],
                 mask=[ True, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__init': masked_array(data=[--, None, --, --],
                 mask=[ True, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__learning_rate': masked_array(data=[--, 0.1, --, --],
                 mask=[ True, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__loss': masked_array(data=[--, 'squared_error', --, --],
                 mask=[ True, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__n_iter_no_change': masked_array(data=[--, None, --, --],
                 mask=[ True, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__subsample': masked_array(data=[--, 1.0, --, --],
                 mask=[ True, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__tol': masked_array(data=[--, 0.0001, 0.0001, --],
                 mask=[ True, False, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__validation_fraction': masked_array(data=[--, 0.1, --, --],
                 mask=[ True, False,  True,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__copy_X': masked_array(data=[--, --, True, --],
                 mask=[ True,  True, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__fit_intercept': masked_array(data=[--, --, True, --],
                 mask=[ True,  True, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__max_iter': masked_array(data=[--, --, 1000, --],
                 mask=[ True,  True, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__positive': masked_array(data=[--, --, False, --],
                 mask=[ True,  True, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__precompute': masked_array(data=[--, --, False, --],
                 mask=[ True,  True, False,  True],
           fill_value='?',
                dtype=object),
    'param_candidate_estimator__estimator__selection': masked_array(data=[--, --, 'cyclic', --],
                 mask=[ True,  True, False,  True],
           fill_value='?',
                dtype=object),
    'params': [{'candidate_estimator': GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                   estimator=RandomForestRegressor(oob_score=True),
                   param_grid={'max_features': ['sqrt', 'log2', None],
                               'n_estimators': [100, 250]},
                   verbose=2),
      'candidate_estimator__cv': ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
      'candidate_estimator__error_score': nan,
      'candidate_estimator__estimator': RandomForestRegressor(oob_score=True),
      'candidate_estimator__estimator__bootstrap': True,
      'candidate_estimator__estimator__ccp_alpha': 0.0,
      'candidate_estimator__estimator__criterion': 'squared_error',
      'candidate_estimator__estimator__max_depth': None,
      'candidate_estimator__estimator__max_features': 1.0,
      'candidate_estimator__estimator__max_leaf_nodes': None,
      'candidate_estimator__estimator__max_samples': None,
      'candidate_estimator__estimator__min_impurity_decrease': 0.0,
      'candidate_estimator__estimator__min_samples_leaf': 1,
      'candidate_estimator__estimator__min_samples_split': 2,
      'candidate_estimator__estimator__min_weight_fraction_leaf': 0.0,
      'candidate_estimator__estimator__monotonic_cst': None,
      'candidate_estimator__estimator__n_estimators': 100,
      'candidate_estimator__estimator__n_jobs': None,
      'candidate_estimator__estimator__oob_score': True,
      'candidate_estimator__estimator__random_state': None,
      'candidate_estimator__estimator__verbose': 0,
      'candidate_estimator__estimator__warm_start': False,
      'candidate_estimator__n_jobs': None,
      'candidate_estimator__param_grid': {'n_estimators': [100, 250],
       'max_features': ['sqrt', 'log2', None]},
      'candidate_estimator__pre_dispatch': '2*n_jobs',
      'candidate_estimator__refit': True,
      'candidate_estimator__return_train_score': False,
      'candidate_estimator__scoring': None,
      'candidate_estimator__verbose': 2},
     {'candidate_estimator': GridSearchCV(estimator=GradientBoostingRegressor(), n_jobs=-1,
                   param_grid={'learning_rate': [0.01, 0.1, 0.25],
                               'max_depth': [3, 6, 9]},
                   verbose=2),
      'candidate_estimator__cv': None,
      'candidate_estimator__error_score': nan,
      'candidate_estimator__estimator': GradientBoostingRegressor(),
      'candidate_estimator__estimator__alpha': 0.9,
      'candidate_estimator__estimator__ccp_alpha': 0.0,
      'candidate_estimator__estimator__criterion': 'friedman_mse',
      'candidate_estimator__estimator__init': None,
      'candidate_estimator__estimator__learning_rate': 0.1,
      'candidate_estimator__estimator__loss': 'squared_error',
      'candidate_estimator__estimator__max_depth': 3,
      'candidate_estimator__estimator__max_features': None,
      'candidate_estimator__estimator__max_leaf_nodes': None,
      'candidate_estimator__estimator__min_impurity_decrease': 0.0,
      'candidate_estimator__estimator__min_samples_leaf': 1,
      'candidate_estimator__estimator__min_samples_split': 2,
      'candidate_estimator__estimator__min_weight_fraction_leaf': 0.0,
      'candidate_estimator__estimator__n_estimators': 100,
      'candidate_estimator__estimator__n_iter_no_change': None,
      'candidate_estimator__estimator__random_state': None,
      'candidate_estimator__estimator__subsample': 1.0,
      'candidate_estimator__estimator__tol': 0.0001,
      'candidate_estimator__estimator__validation_fraction': 0.1,
      'candidate_estimator__estimator__verbose': 0,
      'candidate_estimator__estimator__warm_start': False,
      'candidate_estimator__n_jobs': -1,
      'candidate_estimator__param_grid': {'learning_rate': [0.01, 0.1, 0.25],
       'max_depth': [3, 6, 9]},
      'candidate_estimator__pre_dispatch': '2*n_jobs',
      'candidate_estimator__refit': True,
      'candidate_estimator__return_train_score': False,
      'candidate_estimator__scoring': None,
      'candidate_estimator__verbose': 2},
     {'candidate_estimator': GridSearchCV(estimator=Lasso(), n_jobs=-1, param_grid={'alpha': [0.5, 1, 1.25]},
                   verbose=2),
      'candidate_estimator__cv': None,
      'candidate_estimator__error_score': nan,
      'candidate_estimator__estimator': Lasso(),
      'candidate_estimator__estimator__alpha': 1.0,
      'candidate_estimator__estimator__copy_X': True,
      'candidate_estimator__estimator__fit_intercept': True,
      'candidate_estimator__estimator__max_iter': 1000,
      'candidate_estimator__estimator__positive': False,
      'candidate_estimator__estimator__precompute': False,
      'candidate_estimator__estimator__random_state': None,
      'candidate_estimator__estimator__selection': 'cyclic',
      'candidate_estimator__estimator__tol': 0.0001,
      'candidate_estimator__estimator__warm_start': False,
      'candidate_estimator__n_jobs': -1,
      'candidate_estimator__param_grid': {'alpha': [0.5, 1, 1.25]},
      'candidate_estimator__pre_dispatch': '2*n_jobs',
      'candidate_estimator__refit': True,
      'candidate_estimator__return_train_score': False,
      'candidate_estimator__scoring': None,
      'candidate_estimator__verbose': 2},
     {'candidate_estimator': VotingRegressor(estimators=[('candidate_1',
                                   GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=None, test_size=None, train_size=None),
                                                estimator=RandomForestRegressor(oob_score=True),
                                                param_grid={'max_features': ['sqrt',
                                                                             'log2',
                                                                             None],
                                                            'n_estimators': [100,
                                                                             250]},
                                                verbose=2)),
                                  ('candidate_2',
                                   GridSearchCV(estimator=GradientBoostingRegressor(),
                                                n_jobs=-1,
                                                param_grid={'learning_rate': [0.01,
                                                                              0.1,
                                                                              0.25],
                                                            'max_depth': [3, 6, 9]},
                                                verbose=2)),
                                  ('candidate_3',
                                   GridSearchCV(estimator=Lasso(), n_jobs=-1,
                                                param_grid={'alpha': [0.5, 1, 1.25]},
                                                verbose=2))])}],
    'split0_test_score': array([ 0.42533582,  0.24544115, -0.12495568,  0.12357504]),
    'split1_test_score': array([-0.05928343,  0.16809825, -0.06387796,  0.10860231]),
    'split2_test_score': array([ 0.23517427,  0.2658699 , -0.25506857,  0.10434428]),
    'split3_test_score': array([ 0.3974502 ,  0.29103569, -0.01041259,  0.38418825]),
    'split4_test_score': array([-0.53892232, -1.76136276, -1.24345779, -0.83892865]),
    'split5_test_score': array([-0.0646377 , -0.08589881, -0.5122203 ,  0.09603587]),
    'split6_test_score': array([0.08610483, 0.05930001, 0.00767688, 0.09045774]),
    'split7_test_score': array([ 0.07128832, -0.47734269, -0.09303161,  0.04882746]),
    'split8_test_score': array([ 0.12572295,  0.37029843, -0.02110852,  0.42001619]),
    'split9_test_score': array([ 0.06518707,  0.60159098, -0.22195412,  0.25707454]),
    'mean_test_score': array([ 0.074342  , -0.03229699, -0.25384103,  0.0794193 ]),
    'std_test_score': array([0.25876598, 0.63825062, 0.36159231, 0.32993502]),
    'rank_test_score': array([2, 3, 4, 1])},
   'feature_names_in_': array(['Unnamed: 0', 'gdpsh465', 'bmp1l', 'freeop', 'freetar', 'h65',
          'hm65', 'hf65', 'p65', 'pm65', 'pf65', 's65', 'sm65', 'sf65',
          'fert65', 'mort65', 'lifee065', 'gpop1', 'fert1', 'mort1',
          'invsh41', 'geetot1', 'geerec1', 'gde1', 'govwb1', 'govsh41',
          'gvxdxe41', 'high65', 'highm65', 'highf65', 'highc65', 'highcm65',
          'highcf65', 'human65', 'humanm65', 'humanf65', 'hyr65', 'hyrm65',
          'hyrf65', 'no65', 'nom65', 'nof65', 'pinstab1', 'pop65',
          'worker65', 'pop1565', 'pop6565', 'sec65', 'secm65', 'secf65',
          'secc65', 'seccm65', 'seccf65', 'syr65', 'syrm65', 'syrf65',
          'teapri65', 'teasec65', 'ex1', 'im1', 'xr65', 'tot1'], dtype=object),
   'multimetric_': False,
   'n_features_in_': 62,
   'n_splits_': 10,
   'refit_time_': 29.063441038131714,
   'scorer_': &lt;sklearn.metrics._scorer._PassthroughScorer at 0x251e04f4c40&gt;},
  'paper': 'Paper or other resource for more information',
  'citation': 'Citation details',
  'license': 'License',
  'contact': 'Where to send questions or comments about the model'},
 'intended_use': {'primary_uses': 'Primary intended uses',
  'primary_users': 'Primary intended users',
  'out_of_scope': 'Out-of-scope use cases'},
 'factors': {'relevant': 'Relevant factors',
  'evaluation': 'Evaluation factors'},
 'metrics': {'performance_measures': 'Model performance measures',
  'thresholds': 'Decision thresholds',
  'variation_approaches': 'Variation approaches'},
 'evaluation_data': {'datasets': 'Datasets',
  'motivation': 'Motivation',
  'preprocessing': 'Preprocessing'},
 'training_data': {'training_data': 'Information on training data'},
 'quant_analyses': {'unitary': 'Unitary results',
  'intersectional': 'Intersectional results'},
 'ethical_considerations': {'sensitive_data': 'Does the model use any sensitive data (e.g., protected classes)?',
  'human_life': 'Is the model intended to inform decisions about matters central to human life or flourishing - e.g., health or safety? Or could it be used in such a way?',
  'mitigations': 'What risk mitigation strategies were used during model development?',
  'risks_and_harms': 'What risks may be present in model usage? Try to identify the potential recipients,likelihood, and magnitude of harms. If these cannot be determined, note that they were considered but remain unknown',
  'use_cases': 'Are there any known model use cases that are especially fraught?',
  'additional_information': 'If possible, this section should also include any additional ethical considerations that went into model development, for example, review by an external board, or testing with a specific community.'},
 'caveats_recommendations': {'caveats': 'For example, did the results suggest any further testing? Were there any relevant groups that were not represented in the evaluation dataset?',
  'recommendations': 'Are there additional recommendations for model use? What are the ideal characteristics of an evaluation dataset for this model?'}}</code></pre>
</div>
</div>
<p>And as before, any remaining open questions can be viewed and answered using the same methods as above.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-BARRO19941" class="csl-entry" role="listitem">
Barro, Robert J., and Jong-Wha Lee. 1994. <span>“Sources of Economic Growth.”</span> <em>Carnegie-Rochester Conference Series on Public Policy</em> 40: 1–46. <a href="https://doi.org/10.1016/0167-2231(94)90002-7">https://doi.org/10.1016/0167-2231(94)90002-7</a>.
</div>
<div id="ref-belloni2011inference" class="csl-entry" role="listitem">
Belloni, Alexandre, Victor Chernozhukov, and Christian Hansen. 2011. <span>“Inference for High-Dimensional Sparse Econometric Models.”</span> <em>arXiv Preprint arXiv:1201.0220</em>.
</div>
<div id="ref-giannone2021illusion" class="csl-entry" role="listitem">
Giannone, Domenico, Michele Lenza, and Giorgio E Primiceri. 2021. <span>“Economic Predictions with Big Data: The Illusion of Sparsity.”</span> <em>Econometrica</em> 89 (5): 2409–37.
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // default icon
          link.classList.add("external");
      }
    }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb60" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> An illustration with @BARRO19941</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="an">output-file:</span><span class="co"> barrolee1994.html</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Using gingado to understand economic growth</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> Douglas K. G. Araujo</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="an">code-fold:</span><span class="co"> show</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="an">code-tools:</span><span class="co"> true</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a><span class="an">jupyter:</span><span class="co"> python3</span></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a><span class="an">warning:</span><span class="co"> false</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a>This notebook showcases one possible use of <span class="in">`gingado`</span> by estimating economic growth across countries, using the dataset studied by @BARRO19941. You can run this notebook interactively, by clicking on the appropriate link above.</span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>This dataset has been widely studied in economics. @belloni2011inference and @giannone2021illusion are two studies of this dataset that are most related to machine learning.</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a>This notebook will use <span class="in">`gingado`</span> to compare quickly setup a well-performing machine learning model and use its results as evidence to support the conditional convergence hypothesis; compare different classes of models (and their combination in a single model), and use and document the best performing alternative. </span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a>Because the notebook is for pedagogical purposes only, please bear in mind some aspects of the machine learning workflow (such as carefully thinking about the cross-validation strategy) are glossed over in this notebook. Also, only the key academic references are cited; more references can be found in the papers mentioned in this example.</span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a>For a more thorough description of <span class="in">`gingado`</span>, please refer to the package's <span class="co">[</span><span class="ot">website</span><span class="co">](https://github.com/bis-med-it/gingado)</span> and to the academic <span class="co">[</span><span class="ot">material</span><span class="co">](https://www.github.com/dkgaraujo/gingado_comms)</span> about it.</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## Setting the stage</span></span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a>We will import packages as the work progresses. This will help highlight the specific steps in the workflow that <span class="in">`gingado`</span> can be helpful with.</span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a>The data is available in the <span class="co">[</span><span class="ot">online annex</span><span class="co">](https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA17842)</span> to @giannone2021illusion. In that paper, this dataset corresponds to what the authors call "macro2". The original data, along with more information on the variables, can be found in <span class="co">[</span><span class="ot">this NBER website</span><span class="co">](http://www2.nber.org/pub/barro.lee/)</span>. A very helpful codebook is found <span class="co">[</span><span class="ot">in this repo</span><span class="co">](https://github.com/bizmaercq/Do-Poor-Countries-Grow-Faster-than-Rich-Countries/blob/master/data/Codebook.txt)</span>.</span>
<span id="cb60-33"><a href="#cb60-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-36"><a href="#cb60-36" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-37"><a href="#cb60-37" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gingado.datasets <span class="im">import</span> load_BarroLee_1994</span>
<span id="cb60-38"><a href="#cb60-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-39"><a href="#cb60-39" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> load_BarroLee_1994()</span>
<span id="cb60-40"><a href="#cb60-40" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-41"><a href="#cb60-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-42"><a href="#cb60-42" aria-hidden="true" tabindex="-1"></a>The dataset contains explanatory variables representing per-capita growth between 1960 and 1985, for 90 countries.</span>
<span id="cb60-43"><a href="#cb60-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-46"><a href="#cb60-46" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-47"><a href="#cb60-47" aria-hidden="true" tabindex="-1"></a>X.columns</span>
<span id="cb60-48"><a href="#cb60-48" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-49"><a href="#cb60-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-52"><a href="#cb60-52" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-53"><a href="#cb60-53" aria-hidden="true" tabindex="-1"></a>X.head().T</span>
<span id="cb60-54"><a href="#cb60-54" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-55"><a href="#cb60-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-56"><a href="#cb60-56" aria-hidden="true" tabindex="-1"></a>The outcome variable is represented here:</span>
<span id="cb60-57"><a href="#cb60-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-60"><a href="#cb60-60" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-61"><a href="#cb60-61" aria-hidden="true" tabindex="-1"></a>y.plot.hist(bins<span class="op">=</span><span class="dv">90</span>, title<span class="op">=</span><span class="st">'GDP growth'</span>)</span>
<span id="cb60-62"><a href="#cb60-62" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-63"><a href="#cb60-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-64"><a href="#cb60-64" aria-hidden="true" tabindex="-1"></a><span class="fu">## Establishing a benchmark model</span></span>
<span id="cb60-65"><a href="#cb60-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-66"><a href="#cb60-66" aria-hidden="true" tabindex="-1"></a>Generally speaking, it is a good idea to establish a benchmark model at the first stages of development of the machine learning model. <span class="in">`gingado`</span> offers a class of automatic benchmarks that can be used off-the-shelf depending on the task at hand: <span class="in">`RegressionBenchmark`</span> and <span class="in">`ClassificationBenchmark`</span>. It is also good to keep in mind that more advanced users can create their own benchmark on top of a base class provided by <span class="in">`gingado`</span>: <span class="in">`ggdBenchmark`</span>.</span>
<span id="cb60-67"><a href="#cb60-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-68"><a href="#cb60-68" aria-hidden="true" tabindex="-1"></a>For this application, since we are interested in running a regression task, we will use <span class="in">`RegressionBenchmark`</span>:</span>
<span id="cb60-69"><a href="#cb60-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-72"><a href="#cb60-72" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-73"><a href="#cb60-73" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gingado.benchmark <span class="im">import</span> RegressionBenchmark</span>
<span id="cb60-74"><a href="#cb60-74" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-75"><a href="#cb60-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-76"><a href="#cb60-76" aria-hidden="true" tabindex="-1"></a>What this object does is the following:</span>
<span id="cb60-77"><a href="#cb60-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-78"><a href="#cb60-78" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>it creates a random forest</span>
<span id="cb60-79"><a href="#cb60-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-80"><a href="#cb60-80" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>three different versions of the random forest are trained on the user data</span>
<span id="cb60-81"><a href="#cb60-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-82"><a href="#cb60-82" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>the version that performs better is chosen as the benchmark</span>
<span id="cb60-83"><a href="#cb60-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-84"><a href="#cb60-84" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>right after it is trained, the benchmark is documented using <span class="in">`gingado`</span>'s <span class="in">`ModelCard`</span> documenter.</span>
<span id="cb60-85"><a href="#cb60-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-86"><a href="#cb60-86" aria-hidden="true" tabindex="-1"></a>The user can easily change the parameters above. For example, instead of a random forest the user might prefer a neural network as the benchmark. Or, in lieu of the default parameters provided by <span class="in">`gingado`</span>, users might have their own idea of what could be a reasonable parameter space to search.</span>
<span id="cb60-87"><a href="#cb60-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-88"><a href="#cb60-88" aria-hidden="true" tabindex="-1"></a>Random forests are chosen as the go-to benchmark algorithm because of their reasonably good performance in a wide variety of settings, the fact that they don't require much data transformation (ie, normalising the data to have zero mean and one standard deviation), and by virtue of their relatively transparency about the importance of each regressor.</span>
<span id="cb60-89"><a href="#cb60-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-90"><a href="#cb60-90" aria-hidden="true" tabindex="-1"></a>The first step is to initialise the benchmark object. At this time, we pass some arguments about how we want it to behave. In this case, we set the verbosity level to produce output related to each alternative considered. Then we fit it to the data.</span>
<span id="cb60-91"><a href="#cb60-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-94"><a href="#cb60-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-95"><a href="#cb60-95" aria-hidden="true" tabindex="-1"></a><span class="co">#####</span></span>
<span id="cb60-96"><a href="#cb60-96" aria-hidden="true" tabindex="-1"></a><span class="co">#####</span></span>
<span id="cb60-97"><a href="#cb60-97" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb60-98"><a href="#cb60-98" aria-hidden="true" tabindex="-1"></a>rfr <span class="op">=</span> RandomForestRegressor()</span>
<span id="cb60-99"><a href="#cb60-99" aria-hidden="true" tabindex="-1"></a>rfr.fit(X, y)</span>
<span id="cb60-100"><a href="#cb60-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-101"><a href="#cb60-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-104"><a href="#cb60-104" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-105"><a href="#cb60-105" aria-hidden="true" tabindex="-1"></a>benchmark <span class="op">=</span> RegressionBenchmark(verbose_grid<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb60-106"><a href="#cb60-106" aria-hidden="true" tabindex="-1"></a>benchmark.fit(X, y)</span>
<span id="cb60-107"><a href="#cb60-107" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-108"><a href="#cb60-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-109"><a href="#cb60-109" aria-hidden="true" tabindex="-1"></a>As we can see above, with a few lines we have trained a random forest on the dataset. In this case, the benchmark was the better of six versions of the random forest, according to the default hyperparameters: 100 and 250 estimators were alternated with models for which the maximum number of regressors analysed by individual trees changesd fom the maximum, a square root and a log of the number of regressors. They were each trained using a 5-fold cross-validation. </span>
<span id="cb60-110"><a href="#cb60-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-111"><a href="#cb60-111" aria-hidden="true" tabindex="-1"></a>Let's see which one was the best performing in this case, and hence our benchmark model:</span>
<span id="cb60-112"><a href="#cb60-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-115"><a href="#cb60-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-116"><a href="#cb60-116" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(benchmark.benchmark.cv_results_).T</span>
<span id="cb60-117"><a href="#cb60-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-118"><a href="#cb60-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-119"><a href="#cb60-119" aria-hidden="true" tabindex="-1"></a>The values above are calculated with $R^2$, the default scoring function for a random forest from the <span class="in">`scikit-learn`</span> package. Suppose that instead we would like a benchmark model that is optimised on the maximum error, ie a benchmark that minimises the worst deviation from prediction to ground truth for all the sample. These are the steps that we would take. Note that a more complete list of ready-made scoring parameters and how to create your own function can be found <span class="co">[</span><span class="ot">here</span><span class="co">](https://scikit-learn.org/stable/modules/model_evaluation.html#)</span>.</span>
<span id="cb60-120"><a href="#cb60-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-123"><a href="#cb60-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-124"><a href="#cb60-124" aria-hidden="true" tabindex="-1"></a>benchmark_lower_worsterror <span class="op">=</span> RegressionBenchmark(scoring<span class="op">=</span><span class="st">'max_error'</span>, verbose_grid<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb60-125"><a href="#cb60-125" aria-hidden="true" tabindex="-1"></a>benchmark_lower_worsterror.fit(X, y)</span>
<span id="cb60-126"><a href="#cb60-126" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-127"><a href="#cb60-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-130"><a href="#cb60-130" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-131"><a href="#cb60-131" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(benchmark_lower_worsterror.benchmark.cv_results_).T</span>
<span id="cb60-132"><a href="#cb60-132" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-133"><a href="#cb60-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-134"><a href="#cb60-134" aria-hidden="true" tabindex="-1"></a>Now we even have two benchmark models.</span>
<span id="cb60-135"><a href="#cb60-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-136"><a href="#cb60-136" aria-hidden="true" tabindex="-1"></a>We could further tweak and adjust them, but one of the ideas behind having a benchmark is that it is simple and easy to set up. </span>
<span id="cb60-137"><a href="#cb60-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-138"><a href="#cb60-138" aria-hidden="true" tabindex="-1"></a>Let's retain only the first benchmark, for simplicity, and now look at the predictions, comparing them to the original growth values.</span>
<span id="cb60-139"><a href="#cb60-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-142"><a href="#cb60-142" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-143"><a href="#cb60-143" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> benchmark.predict(X)</span>
<span id="cb60-144"><a href="#cb60-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-145"><a href="#cb60-145" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb60-146"><a href="#cb60-146" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb60-147"><a href="#cb60-147" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb60-148"><a href="#cb60-148" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(</span>
<span id="cb60-149"><a href="#cb60-149" aria-hidden="true" tabindex="-1"></a>        x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>,</span>
<span id="cb60-150"><a href="#cb60-150" aria-hidden="true" tabindex="-1"></a>         grid<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb60-151"><a href="#cb60-151" aria-hidden="true" tabindex="-1"></a>         title<span class="op">=</span><span class="st">'Actual and predicted outcome'</span>,</span>
<span id="cb60-152"><a href="#cb60-152" aria-hidden="true" tabindex="-1"></a>         xlabel<span class="op">=</span><span class="st">'actual GDP growth'</span>,</span>
<span id="cb60-153"><a href="#cb60-153" aria-hidden="true" tabindex="-1"></a>         ylabel<span class="op">=</span><span class="st">'predicted GDP growth'</span>)</span>
<span id="cb60-154"><a href="#cb60-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-155"><a href="#cb60-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-156"><a href="#cb60-156" aria-hidden="true" tabindex="-1"></a>And now a histogram of the benchmark's errors:</span>
<span id="cb60-157"><a href="#cb60-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-160"><a href="#cb60-160" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-161"><a href="#cb60-161" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>, title<span class="op">=</span><span class="st">'Residual'</span>)</span>
<span id="cb60-162"><a href="#cb60-162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-163"><a href="#cb60-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-164"><a href="#cb60-164" aria-hidden="true" tabindex="-1"></a>Since the benchmark is a random forest model, we can see what are the most important regressors, measured as the average reduction in impurity across the trees in the random forest that actually use that particular regressor. They are scaled so that the sum for all features is one. Higher importance amounts indicate that that particular regressor is a more important contributor to the final prediction.</span>
<span id="cb60-165"><a href="#cb60-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-168"><a href="#cb60-168" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-169"><a href="#cb60-169" aria-hidden="true" tabindex="-1"></a>regressor_importance <span class="op">=</span> pd.DataFrame(</span>
<span id="cb60-170"><a href="#cb60-170" aria-hidden="true" tabindex="-1"></a>    benchmark.benchmark.best_estimator_.feature_importances_, </span>
<span id="cb60-171"><a href="#cb60-171" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>X.columns, </span>
<span id="cb60-172"><a href="#cb60-172" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"Importance"</span>]</span>
<span id="cb60-173"><a href="#cb60-173" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb60-174"><a href="#cb60-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-175"><a href="#cb60-175" aria-hidden="true" tabindex="-1"></a>regressor_importance.sort_values(by<span class="op">=</span><span class="st">"Importance"</span>, ascending<span class="op">=</span><span class="va">False</span>) <span class="op">\</span></span>
<span id="cb60-176"><a href="#cb60-176" aria-hidden="true" tabindex="-1"></a>    .plot.bar(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span>), title<span class="op">=</span><span class="st">'Regressor importance'</span>)</span>
<span id="cb60-177"><a href="#cb60-177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-178"><a href="#cb60-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-179"><a href="#cb60-179" aria-hidden="true" tabindex="-1"></a>From the graph above, we can see that the regressor <span class="in">`bmp1l`</span> (black-market premium on foreign exchange) predominates. Interestingly, @belloni2011inference using squared-root lasso also find this regressor to be important.</span>
<span id="cb60-180"><a href="#cb60-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-181"><a href="#cb60-181" aria-hidden="true" tabindex="-1"></a><span class="fu">## Testing the conditional converge hypothesis</span></span>
<span id="cb60-182"><a href="#cb60-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-183"><a href="#cb60-183" aria-hidden="true" tabindex="-1"></a>Now we can leverage our automatic benchmark model to test the conditional converge hypothesis - ie, the preposition that countries with lower starting GDP tend to grow faster than other *comparable* countries. In other words, this hypothesis predicts that when GDP growth is regressed on the level of past GDP and on an adequate set of covariates $X$, the coefficient on past GDP levels are negative.</span>
<span id="cb60-184"><a href="#cb60-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-185"><a href="#cb60-185" aria-hidden="true" tabindex="-1"></a>Since we have the results for the importance of each regressor in separating countries by their growth result, we can compare the estimated coefficient for GDP levels in regressions that include different regressors in the vector $X$. To maintain this example a simple exercise, the following three models are estimated:</span>
<span id="cb60-186"><a href="#cb60-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-187"><a href="#cb60-187" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$X$ contains the five most important regressors, as estimated by the benchmark model (see the graph above)</span>
<span id="cb60-188"><a href="#cb60-188" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$X$ contains the five *least* important regressors, from the same estimation as above</span>
<span id="cb60-189"><a href="#cb60-189" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>$X$ is the empty set - in other words, this is a simple equation on GDP growth on GDP levels</span>
<span id="cb60-190"><a href="#cb60-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-191"><a href="#cb60-191" aria-hidden="true" tabindex="-1"></a>A result that would be consistent with the *conditionality* of the conditional convergence hypothesis is the first equation resulting in a negative coefficient for starting GDP, while the following two equations may not necessarily be successful in identifying a negative coefficient. This is because the least important regressors are not likely to have sufficient predictive power to separate countries into comparable groups.</span>
<span id="cb60-192"><a href="#cb60-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-193"><a href="#cb60-193" aria-hidden="true" tabindex="-1"></a>The five more and less important regressors are:</span>
<span id="cb60-194"><a href="#cb60-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-197"><a href="#cb60-197" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-198"><a href="#cb60-198" aria-hidden="true" tabindex="-1"></a>top_five <span class="op">=</span> regressor_importance.sort_values(by<span class="op">=</span><span class="st">"Importance"</span>, ascending<span class="op">=</span><span class="va">False</span>).head(<span class="dv">5</span>)</span>
<span id="cb60-199"><a href="#cb60-199" aria-hidden="true" tabindex="-1"></a>bottom_five <span class="op">=</span> regressor_importance.sort_values(by<span class="op">=</span><span class="st">"Importance"</span>, ascending<span class="op">=</span><span class="va">True</span>).head(<span class="dv">5</span>)</span>
<span id="cb60-200"><a href="#cb60-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-201"><a href="#cb60-201" aria-hidden="true" tabindex="-1"></a>top_five, bottom_five</span>
<span id="cb60-202"><a href="#cb60-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-203"><a href="#cb60-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-206"><a href="#cb60-206" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-207"><a href="#cb60-207" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb60-208"><a href="#cb60-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-209"><a href="#cb60-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-212"><a href="#cb60-212" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-213"><a href="#cb60-213" aria-hidden="true" tabindex="-1"></a>gdp_level <span class="op">=</span> <span class="st">'gdpsh465'</span></span>
<span id="cb60-214"><a href="#cb60-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-215"><a href="#cb60-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-218"><a href="#cb60-218" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-219"><a href="#cb60-219" aria-hidden="true" tabindex="-1"></a>X_topfive <span class="op">=</span> X[[gdp_level] <span class="op">+</span> <span class="bu">list</span>(top_five.index)]</span>
<span id="cb60-220"><a href="#cb60-220" aria-hidden="true" tabindex="-1"></a>X_topfive <span class="op">=</span> sm.add_constant(X_topfive)</span>
<span id="cb60-221"><a href="#cb60-221" aria-hidden="true" tabindex="-1"></a>X_topfive.head()</span>
<span id="cb60-222"><a href="#cb60-222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-223"><a href="#cb60-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-226"><a href="#cb60-226" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-227"><a href="#cb60-227" aria-hidden="true" tabindex="-1"></a>X_bottomfive <span class="op">=</span> X[[gdp_level] <span class="op">+</span> <span class="bu">list</span>(bottom_five.index)]</span>
<span id="cb60-228"><a href="#cb60-228" aria-hidden="true" tabindex="-1"></a>X_bottomfive <span class="op">=</span> sm.add_constant(X_bottomfive)</span>
<span id="cb60-229"><a href="#cb60-229" aria-hidden="true" tabindex="-1"></a>X_bottomfive.head()</span>
<span id="cb60-230"><a href="#cb60-230" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-231"><a href="#cb60-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-234"><a href="#cb60-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-235"><a href="#cb60-235" aria-hidden="true" tabindex="-1"></a>X_onlyGDPlevel <span class="op">=</span> sm.add_constant(X[gdp_level])</span>
<span id="cb60-236"><a href="#cb60-236" aria-hidden="true" tabindex="-1"></a>X_onlyGDPlevel.head()</span>
<span id="cb60-237"><a href="#cb60-237" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-238"><a href="#cb60-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-241"><a href="#cb60-241" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-242"><a href="#cb60-242" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> <span class="bu">dict</span>(</span>
<span id="cb60-243"><a href="#cb60-243" aria-hidden="true" tabindex="-1"></a>    topfive <span class="op">=</span> sm.OLS(y, X_topfive).fit(),</span>
<span id="cb60-244"><a href="#cb60-244" aria-hidden="true" tabindex="-1"></a>    bottomfive <span class="op">=</span> sm.OLS(y, X_bottomfive).fit(),</span>
<span id="cb60-245"><a href="#cb60-245" aria-hidden="true" tabindex="-1"></a>    onlyGDPlevel <span class="op">=</span> sm.OLS(y, X_onlyGDPlevel).fit()</span>
<span id="cb60-246"><a href="#cb60-246" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb60-247"><a href="#cb60-247" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-248"><a href="#cb60-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-251"><a href="#cb60-251" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-252"><a href="#cb60-252" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> pd.DataFrame({name: model.conf_int().loc[gdp_level] <span class="cf">for</span> name, model <span class="kw">in</span> models.items()})</span>
<span id="cb60-253"><a href="#cb60-253" aria-hidden="true" tabindex="-1"></a>coefs.loc[<span class="fl">0.5</span>] <span class="op">=</span> [model.params[gdp_level] <span class="cf">for</span> _, model <span class="kw">in</span> models.items()]</span>
<span id="cb60-254"><a href="#cb60-254" aria-hidden="true" tabindex="-1"></a>coefs <span class="op">=</span> coefs.sort_index().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-255"><a href="#cb60-255" aria-hidden="true" tabindex="-1"></a>coefs.index <span class="op">=</span> [<span class="st">'[0.025'</span>, <span class="st">'coef on GDP levels'</span>, <span class="st">'0.975]'</span>]</span>
<span id="cb60-256"><a href="#cb60-256" aria-hidden="true" tabindex="-1"></a>coefs</span>
<span id="cb60-257"><a href="#cb60-257" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-258"><a href="#cb60-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-259"><a href="#cb60-259" aria-hidden="true" tabindex="-1"></a>The equation using the top five regressors in explanatory power yielded a coefficient that is statistically speaking negative under the usual confidence interval levels. In contrast, the regression using the bottom five regressors failed to maintain that level of statistical significance (although the coefficient point estimate was still negative). And finally the regression on GDP level solely resulted, as in the past literature, on a point estimate that is also statistically not different than zero.</span>
<span id="cb60-260"><a href="#cb60-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-261"><a href="#cb60-261" aria-hidden="true" tabindex="-1"></a>These results above offer a different way to add evidence to the conditional convergence hypothesis. In particular, with the help of <span class="in">`gingado`</span>'s <span class="in">`RegressionBenchmark`</span> model, it is possible to identify which covariates can meaningfully serve as covariates in a growth equation from those that cannot. This is important because if the covariate selection for some reason included only variables with little explanatory power instead of the most relevant ones, an economist might erroneously reach a different conclusion.</span>
<span id="cb60-262"><a href="#cb60-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-263"><a href="#cb60-263" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model documentation</span></span>
<span id="cb60-264"><a href="#cb60-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-265"><a href="#cb60-265" aria-hidden="true" tabindex="-1"></a>Importantly for model documentation, the benchmark already has some baseline documentation set up. If the user wishes, they can use that as a basis to document their model. Note that the output is in a raw format that is suitable for machine reading and writing. Intermediary and advanced users may wish to use that format to construct personalised forms, documents, etc.</span>
<span id="cb60-266"><a href="#cb60-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-269"><a href="#cb60-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-270"><a href="#cb60-270" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.show_json()</span>
<span id="cb60-271"><a href="#cb60-271" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-272"><a href="#cb60-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-273"><a href="#cb60-273" aria-hidden="true" tabindex="-1"></a>Since there is some information in the model documentation that was automatically added, we might want to concentrate on the fields in the model card that are yet to be answered. Actually, this is the purpose of <span class="in">`gingado`</span>'s automatic documentation: to afford users more time so they can invest, if they want, on model documentation.</span>
<span id="cb60-274"><a href="#cb60-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-277"><a href="#cb60-277" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-278"><a href="#cb60-278" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.open_questions()</span>
<span id="cb60-279"><a href="#cb60-279" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-280"><a href="#cb60-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-281"><a href="#cb60-281" aria-hidden="true" tabindex="-1"></a>Let's fill some information:</span>
<span id="cb60-282"><a href="#cb60-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-285"><a href="#cb60-285" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-286"><a href="#cb60-286" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.fill_info({</span>
<span id="cb60-287"><a href="#cb60-287" aria-hidden="true" tabindex="-1"></a>    <span class="st">'intended_use'</span>: {</span>
<span id="cb60-288"><a href="#cb60-288" aria-hidden="true" tabindex="-1"></a>        <span class="st">'primary_uses'</span>: <span class="st">'This model is trained for pedagogical uses only.'</span>,</span>
<span id="cb60-289"><a href="#cb60-289" aria-hidden="true" tabindex="-1"></a>        <span class="st">'primary_users'</span>: <span class="st">'Everyone is welcome to follow the description showing the development of this benchmark.'</span></span>
<span id="cb60-290"><a href="#cb60-290" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb60-291"><a href="#cb60-291" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb60-292"><a href="#cb60-292" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-293"><a href="#cb60-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-294"><a href="#cb60-294" aria-hidden="true" tabindex="-1"></a>Note the format, based on a Python dictionary. In particular, the <span class="in">`open_questions`</span> method results include keys divided by double underscores. As seen above, these should be interpreted as different levels of the documentation template, leading to a nested dictionary. </span>
<span id="cb60-295"><a href="#cb60-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-296"><a href="#cb60-296" aria-hidden="true" tabindex="-1"></a>Now when we confirm that the questions answered above are no longer "open questions":</span>
<span id="cb60-297"><a href="#cb60-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-300"><a href="#cb60-300" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-301"><a href="#cb60-301" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.open_questions()</span>
<span id="cb60-302"><a href="#cb60-302" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-303"><a href="#cb60-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-304"><a href="#cb60-304" aria-hidden="true" tabindex="-1"></a>If we want, at any time we can save the documentation to a local JSON file, as well as read another document.</span>
<span id="cb60-305"><a href="#cb60-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-306"><a href="#cb60-306" aria-hidden="true" tabindex="-1"></a><span class="fu">## Trying out model alternatives</span></span>
<span id="cb60-307"><a href="#cb60-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-308"><a href="#cb60-308" aria-hidden="true" tabindex="-1"></a>The benchmark model may be enough for some analyses, or maybe the user is interested in using the benchmark to explore the data and have an understanding of the importance of each regressor, to concentrate their work on data that can be meaningful for their purposes. But oftentimes a user will want to seek a machine learning model that performs as well as possible.</span>
<span id="cb60-309"><a href="#cb60-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-310"><a href="#cb60-310" aria-hidden="true" tabindex="-1"></a>For users that want to manually create other models, <span class="in">`gingado`</span> allows the possibility of comparing them with the benchmark. If the user model is better, it becomes the new benchmark!</span>
<span id="cb60-311"><a href="#cb60-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-312"><a href="#cb60-312" aria-hidden="true" tabindex="-1"></a>For the following analyses, we will use K-fold as cross-validation, with 5 splits of the sample.</span>
<span id="cb60-313"><a href="#cb60-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-314"><a href="#cb60-314" aria-hidden="true" tabindex="-1"></a><span class="fu">### First candidate: a gradient boosting tree</span></span>
<span id="cb60-315"><a href="#cb60-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-318"><a href="#cb60-318" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-319"><a href="#cb60-319" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb60-320"><a href="#cb60-320" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb60-321"><a href="#cb60-321" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb60-322"><a href="#cb60-322" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-323"><a href="#cb60-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-326"><a href="#cb60-326" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-327"><a href="#cb60-327" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb60-328"><a href="#cb60-328" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">0.25</span>],</span>
<span id="cb60-329"><a href="#cb60-329" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">9</span>]</span>
<span id="cb60-330"><a href="#cb60-330" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb60-331"><a href="#cb60-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-332"><a href="#cb60-332" aria-hidden="true" tabindex="-1"></a>reg_gradbooster <span class="op">=</span> GradientBoostingRegressor()</span>
<span id="cb60-333"><a href="#cb60-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-334"><a href="#cb60-334" aria-hidden="true" tabindex="-1"></a>gradboosterg_grid <span class="op">=</span> GridSearchCV(</span>
<span id="cb60-335"><a href="#cb60-335" aria-hidden="true" tabindex="-1"></a>    reg_gradbooster,</span>
<span id="cb60-336"><a href="#cb60-336" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb60-337"><a href="#cb60-337" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb60-338"><a href="#cb60-338" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span></span>
<span id="cb60-339"><a href="#cb60-339" aria-hidden="true" tabindex="-1"></a>).fit(X, y)</span>
<span id="cb60-340"><a href="#cb60-340" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-341"><a href="#cb60-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-344"><a href="#cb60-344" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-345"><a href="#cb60-345" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> gradboosterg_grid.predict(X)</span>
<span id="cb60-346"><a href="#cb60-346" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb60-347"><a href="#cb60-347" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb60-348"><a href="#cb60-348" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb60-349"><a href="#cb60-349" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>, grid<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-350"><a href="#cb60-350" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-351"><a href="#cb60-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-354"><a href="#cb60-354" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-355"><a href="#cb60-355" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb60-356"><a href="#cb60-356" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-357"><a href="#cb60-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-358"><a href="#cb60-358" aria-hidden="true" tabindex="-1"></a><span class="fu">### Second candidate: lasso</span></span>
<span id="cb60-359"><a href="#cb60-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-362"><a href="#cb60-362" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-363"><a href="#cb60-363" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb60-364"><a href="#cb60-364" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-365"><a href="#cb60-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-368"><a href="#cb60-368" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-369"><a href="#cb60-369" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb60-370"><a href="#cb60-370" aria-hidden="true" tabindex="-1"></a>    <span class="st">'alpha'</span>: [<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="fl">1.25</span>],</span>
<span id="cb60-371"><a href="#cb60-371" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb60-372"><a href="#cb60-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-373"><a href="#cb60-373" aria-hidden="true" tabindex="-1"></a>reg_lasso <span class="op">=</span> Lasso(fit_intercept<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-374"><a href="#cb60-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-375"><a href="#cb60-375" aria-hidden="true" tabindex="-1"></a>lasso_grid <span class="op">=</span> GridSearchCV(</span>
<span id="cb60-376"><a href="#cb60-376" aria-hidden="true" tabindex="-1"></a>    reg_lasso,</span>
<span id="cb60-377"><a href="#cb60-377" aria-hidden="true" tabindex="-1"></a>    param_grid,</span>
<span id="cb60-378"><a href="#cb60-378" aria-hidden="true" tabindex="-1"></a>    n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb60-379"><a href="#cb60-379" aria-hidden="true" tabindex="-1"></a>    verbose<span class="op">=</span><span class="dv">2</span></span>
<span id="cb60-380"><a href="#cb60-380" aria-hidden="true" tabindex="-1"></a>).fit(X, y)</span>
<span id="cb60-381"><a href="#cb60-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-382"><a href="#cb60-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-385"><a href="#cb60-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-386"><a href="#cb60-386" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> lasso_grid.predict(X)</span>
<span id="cb60-387"><a href="#cb60-387" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb60-388"><a href="#cb60-388" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb60-389"><a href="#cb60-389" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb60-390"><a href="#cb60-390" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>, grid<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-391"><a href="#cb60-391" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-392"><a href="#cb60-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-395"><a href="#cb60-395" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-396"><a href="#cb60-396" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb60-397"><a href="#cb60-397" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-398"><a href="#cb60-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-399"><a href="#cb60-399" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparing the models with the benchmark</span></span>
<span id="cb60-400"><a href="#cb60-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-401"><a href="#cb60-401" aria-hidden="true" tabindex="-1"></a><span class="in">`gingado`</span> allows users to compare different candidate models with the existing benchmark in a very simple way: using the <span class="in">`compare`</span> method.</span>
<span id="cb60-402"><a href="#cb60-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-405"><a href="#cb60-405" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-406"><a href="#cb60-406" aria-hidden="true" tabindex="-1"></a>candidates <span class="op">=</span> [gradboosterg_grid, lasso_grid]</span>
<span id="cb60-407"><a href="#cb60-407" aria-hidden="true" tabindex="-1"></a>benchmark.compare(X, y, candidates)</span>
<span id="cb60-408"><a href="#cb60-408" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-409"><a href="#cb60-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-410"><a href="#cb60-410" aria-hidden="true" tabindex="-1"></a>The output above clearly indicates that after evaluating the models - and their ensemble together with the existing benchmark - at least one of them was better than the current benchmark. Therefore, it will now be the new benchmark.</span>
<span id="cb60-411"><a href="#cb60-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-414"><a href="#cb60-414" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-415"><a href="#cb60-415" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> benchmark.predict(X)</span>
<span id="cb60-416"><a href="#cb60-416" aria-hidden="true" tabindex="-1"></a>pd.DataFrame({</span>
<span id="cb60-417"><a href="#cb60-417" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y'</span>: y,</span>
<span id="cb60-418"><a href="#cb60-418" aria-hidden="true" tabindex="-1"></a>    <span class="st">'y_pred'</span>: y_pred</span>
<span id="cb60-419"><a href="#cb60-419" aria-hidden="true" tabindex="-1"></a>    }).plot.scatter(x<span class="op">=</span><span class="st">'y'</span>, y<span class="op">=</span><span class="st">'y_pred'</span>, grid<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb60-420"><a href="#cb60-420" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-421"><a href="#cb60-421" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-424"><a href="#cb60-424" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-425"><a href="#cb60-425" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(y <span class="op">-</span> y_pred).plot.hist(bins<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb60-426"><a href="#cb60-426" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-427"><a href="#cb60-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-428"><a href="#cb60-428" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model documentation</span></span>
<span id="cb60-429"><a href="#cb60-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-430"><a href="#cb60-430" aria-hidden="true" tabindex="-1"></a>After this process, we can now see how the model documentation was updated automatically:</span>
<span id="cb60-431"><a href="#cb60-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-434"><a href="#cb60-434" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb60-435"><a href="#cb60-435" aria-hidden="true" tabindex="-1"></a>benchmark.model_documentation.show_json()</span>
<span id="cb60-436"><a href="#cb60-436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb60-437"><a href="#cb60-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-438"><a href="#cb60-438" aria-hidden="true" tabindex="-1"></a>And as before, any remaining open questions can be viewed and answered using the same methods as above.</span>
<span id="cb60-439"><a href="#cb60-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-440"><a href="#cb60-440" aria-hidden="true" tabindex="-1"></a><span class="fu">## References</span></span>
<span id="cb60-441"><a href="#cb60-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-442"><a href="#cb60-442" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb60-443"><a href="#cb60-443" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>